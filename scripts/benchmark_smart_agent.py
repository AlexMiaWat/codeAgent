#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ baseline —Å–æ—Å—Ç–æ—è–Ω–∏—è Smart Agent –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –ó–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –ù–∞–ª–∏—á–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
- –ë–∞–∑–æ–≤—É—é –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å YAML —Ñ–∞–π–ª–æ–≤
- –°—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –≤ llm_settings.yaml
"""

import os
import sys
import yaml
import json
from datetime import datetime
from pathlib import Path

def load_yaml_file(file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ YAML —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        return {"error": str(e), "file": str(file_path)}

def analyze_config_duplication():
    """–ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –º–µ–∂–¥—É config.yaml –∏ agents.yaml"""
    config_path = Path("config/config.yaml")
    agents_path = Path("config/agents.yaml")

    config_data = load_yaml_file(config_path)
    agents_data = load_yaml_file(agents_path)

    issues = []

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ smart_agent –Ω–∞—Å—Ç—Ä–æ–µ–∫
    config_smart = config_data.get("smart_agent", {})
    agents_smart = agents_data.get("smart_agent", {})

    duplicated_keys = set(config_smart.keys()) & set(agents_smart.keys())
    if duplicated_keys:
        issues.append({
            "type": "duplication",
            "description": f"–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ smart_agent: {', '.join(duplicated_keys)}",
            "config_values": {k: config_smart[k] for k in duplicated_keys},
            "agents_values": {k: agents_smart[k] for k in duplicated_keys},
            "recommendation": "–£–±—Ä–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–ª—å–∫–æ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ"
        })

    return issues

def analyze_llm_settings():
    """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ LLM"""
    llm_path = Path("config/llm_settings.yaml")
    llm_data = load_yaml_file(llm_path)

    issues = []

    if "error" in llm_data:
        return [{"type": "error", "description": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ llm_settings.yaml: {llm_data['error']}"}]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = llm_data.get("_stats", {})
    if stats.get("working_count", 0) == 0:
        issues.append({
            "type": "warning",
            "description": "working_count = 0, –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–±–ª–µ–º—ã —Å –º–æ–¥–µ–ª—è–º–∏",
            "current_stats": stats
        })

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–æ—Ä–æ–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
    providers = llm_data.get("providers", {})
    expensive_models = []

    for provider_name, provider_data in providers.items():
        if "models" in provider_data:
            for model in provider_data["models"]:
                if isinstance(model, dict):
                    name = model.get("name", "")
                else:
                    name = str(model)
                if any(keyword in name.lower() for keyword in ["claude", "gpt-4o", "sonnet"]):
                    expensive_models.append(name)

    if expensive_models:
        issues.append({
            "type": "cost_warning",
            "description": f"–ù–∞–π–¥–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –¥–æ—Ä–æ–≥–∏–µ –º–æ–¥–µ–ª–∏: {', '.join(expensive_models)}",
            "recommendation": "–£–±–µ–¥–∏—Ç—å—Å—è –≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–æ—Ä–æ–≥–∏—Ö –º–æ–¥–µ–ª–µ–π"
        })

    return issues

def check_todo_status():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ –≤ todo.md"""
    todo_path = Path("todo.md")

    try:
        with open(todo_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å –∑–∞–¥–∞—á–µ–π 1769114510
        lines = content.split('\n')
        for line in lines:
            if "1769114510" in line:
                if line.startswith("- [x]"):
                    return {"status": "completed", "line": line.strip()}
                elif line.startswith("- [ ]"):
                    return {"status": "pending", "line": line.strip()}
                else:
                    return {"status": "unknown", "line": line.strip()}

        return {"status": "not_found"}

    except Exception as e:
        return {"status": "error", "error": str(e)}

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    print("üîç –ê–Ω–∞–ª–∏–∑ baseline —Å–æ—Å—Ç–æ—è–Ω–∏—è Smart Agent –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    print("=" * 60)

    results = {
        "timestamp": datetime.now().isoformat(),
        "analysis_type": "baseline_check",
        "issues": []
    }

    # 1. –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
    print("üìã –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫...")
    duplication_issues = analyze_config_duplication()
    results["issues"].extend(duplication_issues)
    print(f"   –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {len(duplication_issues)}")

    # 2. –ê–Ω–∞–ª–∏–∑ LLM –Ω–∞—Å—Ç—Ä–æ–µ–∫
    print("ü§ñ –ê–Ω–∞–ª–∏–∑ LLM –Ω–∞—Å—Ç—Ä–æ–µ–∫...")
    llm_issues = analyze_llm_settings()
    results["issues"].extend(llm_issues)
    print(f"   –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º LLM: {len(llm_issues)}")

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏
    print("üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏...")
    todo_status = check_todo_status()
    results["todo_status"] = todo_status
    print(f"   –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏: {todo_status.get('status', 'unknown')}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = f"docs/results/baseline_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print("=" * 60)
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

    # –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüìä –ö–†–ê–¢–ö–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")

    if duplication_issues:
        print(f"‚ö†Ô∏è  –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫: {len(duplication_issues)} –ø—Ä–æ–±–ª–µ–º")
        for issue in duplication_issues:
            print(f"   ‚Ä¢ {issue['description']}")

    if llm_issues:
        print(f"‚ö†Ô∏è  –ü—Ä–æ–±–ª–µ–º—ã LLM: {len(llm_issues)} –ø—Ä–æ–±–ª–µ–º")
        for issue in llm_issues:
            print(f"   ‚Ä¢ {issue['description']}")

    todo_status_desc = todo_status.get('status', 'unknown')
    if todo_status_desc == 'completed':
        print("‚úÖ –ó–∞–¥–∞—á–∞ –æ—Ç–º–µ—á–µ–Ω–∞ –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è")
    elif todo_status_desc == 'pending':
        print("‚è≥ –ó–∞–¥–∞—á–∞ –≤—Å–µ –µ—â–µ –≤ —Ä–∞–±–æ—Ç–µ")
    else:
        print(f"‚ùì –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏: {todo_status_desc}")

    return results

if __name__ == "__main__":
    main()