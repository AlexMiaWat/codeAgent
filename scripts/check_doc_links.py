#!/usr/bin/env python3
"""
Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑÑÑ‹Ð»Ð¾Ðº Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸

ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð¾Ð², Ð½Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÑÑÑ‹Ð»Ð°ÑŽÑ‚ÑÑ markdown Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹.
"""

import re
import sys
from pathlib import Path
from typing import List, Tuple

# ÐšÐ¾Ñ€ÐµÐ½ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
PROJECT_ROOT = Path(__file__).parent.parent
DOCS_DIR = PROJECT_ROOT / "docs"


def find_markdown_links(content: str, file_path: Path) -> List[Tuple[str, str]]:
    """
    ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð²ÑÐµ markdown ÑÑÑ‹Ð»ÐºÐ¸ Ð² ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ð¼ Ñ„Ð°Ð¹Ð»Ð°
    
    Returns:
        Ð¡Ð¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ÐµÐ¹ (Ñ‚ÐµÐºÑÑ‚ ÑÑÑ‹Ð»ÐºÐ¸, Ð¿ÑƒÑ‚ÑŒ)
    """
    links = []
    
    # ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ markdown ÑÑÑ‹Ð»Ð¾Ðº: [Ñ‚ÐµÐºÑÑ‚](Ð¿ÑƒÑ‚ÑŒ)
    pattern = r'\[([^\]]+)\]\(([^\)]+)\)'
    
    for match in re.finditer(pattern, content):
        link_text = match.group(1)
        link_path = match.group(2)
        
        # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð²Ð½ÐµÑˆÐ½Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸ (http/https)
        if link_path.startswith('http://') or link_path.startswith('https://'):
            continue
        
        # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÐºÐ¾Ñ€Ñ (#)
        if link_path.startswith('#'):
            continue
        
        links.append((link_text, link_path))
    
    return links


def resolve_link_path(link_path: str, base_file: Path) -> Path:
    """
    Ð Ð°Ð·Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð¿ÑƒÑ‚ÑŒ ÑÑÑ‹Ð»ÐºÐ¸ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°
    
    Args:
        link_path: ÐŸÑƒÑ‚ÑŒ Ð¸Ð· ÑÑÑ‹Ð»ÐºÐ¸
        base_file: Ð¤Ð°Ð¹Ð», Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ ÑÑÑ‹Ð»ÐºÐ°
    
    Returns:
        ÐÐ±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ
    """
    # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐºÐ¾Ñ€Ñ Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
    clean_path = link_path.split('#')[0].split('?')[0]
    
    # Ð•ÑÐ»Ð¸ Ð¿ÑƒÑ‚ÑŒ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ Ð¾Ñ‚ ÐºÐ¾Ñ€Ð½Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
    if clean_path.startswith('/'):
        return PROJECT_ROOT / clean_path.lstrip('/')
    
    # ÐžÑ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ
    base_dir = base_file.parent
    # ÐŸÑ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿ÑƒÑ‚Ð¸ Ñ .. ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð°Ð¼Ð¸
    combined = base_dir / clean_path
    parts = list(combined.parts)
    normalized = []

    for part in parts:
        if part == '..':
            if normalized:
                normalized.pop()  # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚
        elif part != '.':
            normalized.append(part)

    normalized_path = Path(*normalized)
    resolved = (PROJECT_ROOT / normalized_path).resolve()

    return resolved


def check_documentation_links() -> Tuple[int, int]:
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð²ÑÐµ ÑÑÑ‹Ð»ÐºÐ¸ Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸
    
    Returns:
        ÐšÐ¾Ñ€Ñ‚ÐµÐ¶ (ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº, ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾ÑˆÐ¸Ð±Ð¾Ðº)
    """
    total_links = 0
    broken_links = 0
    broken_files = []
    
    # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð²ÑÐµ markdown Ñ„Ð°Ð¹Ð»Ñ‹
    md_files = list(DOCS_DIR.rglob('*.md'))
    
    print(f"ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑÑ‹Ð»Ð¾Ðº Ð² {len(md_files)} Ñ„Ð°Ð¹Ð»Ð°Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸...\n")
    
    for md_file in md_files:
        try:
            content = md_file.read_text(encoding='utf-8')
            links = find_markdown_links(content, md_file)
            
            for link_text, link_path in links:
                total_links += 1
                resolved_path = resolve_link_path(link_path, md_file)
                
                if not resolved_path.exists():
                    broken_links += 1
                    broken_files.append({
                        'file': str(md_file.relative_to(PROJECT_ROOT)),
                        'link_text': link_text,
                        'link_path': link_path,
                        'resolved_path': str(resolved_path.relative_to(PROJECT_ROOT))
                    })
                    print(f"âŒ {md_file.relative_to(PROJECT_ROOT)}")
                    print(f"   Ð¡ÑÑ‹Ð»ÐºÐ°: [{link_text}]({link_path})")
                    print(f"   ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ: {resolved_path.relative_to(PROJECT_ROOT)}")
                    print()
        
        except Exception as e:
            print(f"âš ï¸  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ {md_file}: {e}")
    
    # Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
    print("=" * 70)
    print(f"ÐŸÑ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð¾ ÑÑÑ‹Ð»Ð¾Ðº: {total_links}")
    print(f"Ð¡Ð»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº: {broken_links}")
    print(f"ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ…: {((total_links - broken_links) / total_links * 100) if total_links > 0 else 0:.1f}%")
    print("=" * 70)
    
    if broken_links > 0:
        print("\nðŸ“‹ Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº:")
        for item in broken_files[:20]:  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 20
            print(f"  - {item['file']}: [{item['link_text']}]({item['link_path']})")
        if len(broken_files) > 20:
            print(f"  ... Ð¸ ÐµÑ‰Ðµ {len(broken_files) - 20} ÑÑÑ‹Ð»Ð¾Ðº")
    
    return total_links, broken_links


if __name__ == "__main__":
    total, broken = check_documentation_links()
    sys.exit(1 if broken > 0 else 0)
