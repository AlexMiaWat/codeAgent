#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è LearningTool
"""

import sys
import time
import json
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.tools.learning_tool import LearningTool


def test_cache_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è LearningTool")

    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    import tempfile
    with tempfile.TemporaryDirectory(prefix="cache_test_") as temp_dir:
        temp_path = Path(temp_dir)

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        tool = LearningTool(
            experience_dir=str(temp_path / "experience"),
            cache_size=100,
            cache_ttl_seconds=300,
            enable_cache_persistence=True,
            enable_indexing=True
        )

        print("üìù –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
        tasks_data = [
            {"desc": "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞", "patterns": ["testing", "configuration"], "time": 15.5},
            {"desc": "–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π requests –≤ requirements.txt", "patterns": ["dependencies", "requirements"], "time": 8.2},
            {"desc": "–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Python –ø–∞–∫–µ—Ç–∞", "patterns": ["project_structure", "python"], "time": 22.1},
            {"desc": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–º–ø–æ—Ä—Ç–æ–≤ –≤ –º–æ–¥—É–ª–µ utils", "patterns": ["optimization", "imports"], "time": 12.3},
            {"desc": "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è", "patterns": ["logging", "configuration"], "time": 18.7},
            {"desc": "–°–æ–∑–¥–∞–Ω–∏–µ unit —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∞", "patterns": ["testing", "unit_tests"], "time": 25.4},
            {"desc": "–†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö", "patterns": ["refactoring", "data_processing"], "time": 35.2},
            {"desc": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º API", "patterns": ["integration", "api"], "time": 45.8},
            {"desc": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö", "patterns": ["optimization", "database"], "time": 55.1},
            {"desc": "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ CI/CD –ø–∞–π–ø–ª–∞–π–Ω–∞", "patterns": ["ci_cd", "deployment"], "time": 28.9},
        ]

        for i, task in enumerate(tasks_data):
            tool._run("save_experience",
                     task_id=f"perf_task_{i:03d}",
                     task_description=task["desc"],
                     success=True,
                     execution_time=task["time"],
                     patterns=task["patterns"],
                     notes=f"Performance test task {i}")

        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(tasks_data)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á")

        # –¢–µ—Å—Ç 1: –ü–µ—Ä–≤—ã–π –ø–æ–∏—Å–∫ (—Ö–æ–ª–æ–¥–Ω—ã–π –∫—ç—à)
        print("\nüîç –¢–µ—Å—Ç 1: –ü–æ–∏—Å–∫ —Å —Ö–æ–ª–æ–¥–Ω—ã–º –∫—ç—à–µ–º")
        start_time = time.time()
        result1 = tool._run("find_similar_tasks", query="–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        cold_search_time = time.time() - start_time
        print(f"–í—Ä–µ–º—è —Ö–æ–ª–æ–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {cold_search_time:.3f}—Å")
        # –¢–µ—Å—Ç 2: –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ (–≥–æ—Ä—è—á–∏–π –∫—ç—à)
        print("\nüîç –¢–µ—Å—Ç 2: –ü–æ–∏—Å–∫ —Å –≥–æ—Ä—è—á–∏–º –∫—ç—à–µ–º")
        start_time = time.time()
        result2 = tool._run("find_similar_tasks", query="–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        hot_search_time = time.time() - start_time
        print(f"–í—Ä–µ–º—è –≥–æ—Ä—è—á–µ–≥–æ –ø–æ–∏—Å–∫–∞: {hot_search_time:.3f}—Å")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
        assert result1 == result2, "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏"

        # –¢–µ—Å—Ç 3: –†–∞–∑–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∫—ç—à–∞
        print("\nüîç –¢–µ—Å—Ç 3: –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã")
        queries = ["—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", "–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏", "–ø—Ä–æ–µ–∫—Ç–∞", "–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏", "–±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"]

        for query in queries:
            tool._run("find_similar_tasks", query=query)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
        cache_stats = tool.get_cache_stats()
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–æ–≤:")
        print(cache_stats)

        # –¢–µ—Å—Ç 4: –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫—ç—à–∞
        print("\nüíæ –¢–µ—Å—Ç 4: –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫—ç—à–∞")

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä (–∏–º–∏—Ç–∞—Ü–∏—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞)
        tool2 = LearningTool(
            experience_dir=str(temp_path / "experience"),
            cache_size=100,
            cache_ttl_seconds=300,
            enable_cache_persistence=True
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫—ç—à –∑–∞–≥—Ä—É–∑–∏–ª—Å—è
        cache_stats2 = tool2.get_cache_stats()
        print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏:")
        print(cache_stats2)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑ –∫—ç—à–∞
        start_time = time.time()
        result3 = tool2._run("find_similar_tasks", query="–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        persisted_search_time = time.time() - start_time

        assert result1 == result3, "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞"
        print(f"–í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ —Å –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º –∫—ç—à–µ–º: {persisted_search_time:.3f}—Å")
        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        print("\n" + "="*60)
        print("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ö–ï–®–ò–†–û–í–ê–ù–ò–Ø")
        print("="*60)

        print(f"–•–æ–ª–æ–¥–Ω—ã–π –ø–æ–∏—Å–∫: {cold_search_time:.3f}—Å")
        print(f"–ì–æ—Ä—è—á–∏–π –ø–æ–∏—Å–∫: {hot_search_time:.3f}—Å")
        print(f"–ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π –ø–æ–∏—Å–∫: {persisted_search_time:.3f}—Å")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if hot_search_time < cold_search_time:
            improvement = (cold_search_time - hot_search_time) / cold_search_time * 100
            print(f"‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–∫–æ—Ä–∏–ª–æ –ø–æ–∏—Å–∫ –Ω–∞ {improvement:.1f}%")
        else:
            print("‚ö†Ô∏è  –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –ø–æ–∫–∞–∑–∞–ª–æ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º hit rate
        stats_lines = cache_stats.split('\n')
        hit_rate_line = next((line for line in stats_lines if '–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ø–∞–¥–∞–Ω–∏–π' in line), None)
        if hit_rate_line:
            hit_rate = float(hit_rate_line.split(': ')[1].rstrip('%'))
            if hit_rate > 50:
                print(f"‚úÖ –•–æ—Ä–æ—à–∏–π hit rate –∫—ç—à–∞: {hit_rate:.1f}%")
            else:
                print(f"‚ö†Ô∏è  –ù–∏–∑–∫–∏–π hit rate –∫—ç—à–∞: {hit_rate:.1f}%")
        print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")


def test_cache_edge_cases():
    """–¢–µ—Å—Ç –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("\nüî¨ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è")

    import tempfile
    with tempfile.TemporaryDirectory(prefix="cache_edge_test_") as temp_dir:
        temp_path = Path(temp_dir)

        # –¢–µ—Å—Ç —Å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–º –∫—ç—à–µ–º
        tool = LearningTool(
            experience_dir=str(temp_path / "experience"),
            cache_size=1,  # –¢–æ–ª—å–∫–æ 1 —ç–ª–µ–º–µ–Ω—Ç –≤ –∫—ç—à–µ
            cache_ttl_seconds=1,  # TTL 1 —Å–µ–∫—É–Ω–¥–∞
            enable_cache_persistence=False
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É
        tool._run("save_experience",
                 task_id="edge_case_1",
                 task_description="–¢–µ—Å—Ç –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è",
                 success=True,
                 execution_time=1.0,
                 patterns=["edge", "case"],
                 notes="Edge case test")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        queries = ["–≥—Ä–∞–Ω–∏—á–Ω—ã—Ö", "—Å–ª—É—á–∞–µ–≤", "–∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è", "—Ç–µ—Å—Ç–∞", "–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"]

        for query in queries:
            tool._run("find_similar_tasks", query=query)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        cache_stats = tool.get_cache_stats()
        print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö:")
        print(cache_stats)

        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω eviction
        assert "–í—ã—Å–µ–ª–µ–Ω–∏–π –∏–∑ –∫—ç—à–∞:" in cache_stats

        print("‚úÖ –ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


if __name__ == "__main__":
    try:
        test_cache_performance()
        test_cache_edge_cases()
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)