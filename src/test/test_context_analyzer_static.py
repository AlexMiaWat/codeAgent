"""
–°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –¥–ª—è ContextAnalyzerTool - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö, API, —Ñ–æ—Ä–º–∞—Ç–æ–≤
"""

import pytest
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from unittest.mock import Mock, patch, MagicMock
import inspect


class TestContextAnalyzerToolStatic:
    """–°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã ContextAnalyzerTool"""

    def test_context_analyzer_class_attributes(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ ContextAnalyzerTool"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª—è Pydantic –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤ –Ω–∞—à–µ–º –∫–ª–∞—Å—Å–µ)
        model_fields = ContextAnalyzerTool.model_fields
        assert 'name' in model_fields
        assert 'description' in model_fields
        assert 'project_dir' in model_fields
        assert 'docs_dir' in model_fields
        assert 'max_file_size' in model_fields
        assert 'supported_extensions' in model_fields

        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–π
        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            assert tool.name == "ContextAnalyzerTool"
            assert "–∞–Ω–∞–ª–∏–∑" in tool.description.lower()
            assert tool.max_file_size == 1000000
            assert isinstance(tool.supported_extensions, list)

    def test_supported_extensions_list(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–∏—Å–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            expected_extensions = ['.md', '.txt', '.rst', '.py', '.js', '.ts', '.json', '.yaml', '.yml', '.java', '.cpp', '.hpp', '.c', '.h']

            assert tool.supported_extensions == expected_extensions

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å —Ç–æ—á–∫–∏
            for ext in tool.supported_extensions:
                assert ext.startswith('.')
                assert len(ext) > 1

    def test_context_analyzer_initialization(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ContextAnalyzerTool"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool
        import inspect

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É __init__
        init_sig = inspect.signature(ContextAnalyzerTool.__init__)
        expected_params = ['self', 'project_dir', 'docs_dir', 'max_file_size',
                          'supported_extensions', 'supported_languages', 'max_dependency_depth', 'kwargs']

        actual_params = list(init_sig.parameters.keys())
        assert actual_params == expected_params

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        params = init_sig.parameters
        assert params['project_dir'].annotation == str
        assert params['docs_dir'].annotation == str
        assert params['max_file_size'].annotation == int
        # supported_extensions –º–æ–∂–µ—Ç –±—ã—Ç—å None –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    def test_context_analyzer_initialization_defaults(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            assert str(tool.project_dir) == str(project_dir)
            assert str(tool.docs_dir) == str(project_dir / "docs")
            assert tool.max_file_size == 1000000
            # supported_extensions –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            assert tool.supported_extensions is not None
            assert len(tool.supported_extensions) > 0

    def test_context_analyzer_custom_config(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ContextAnalyzerTool"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)
            custom_docs = project_dir / "custom_docs"
            custom_extensions = ['.md', '.py', '.txt']
            custom_max_size = 500000

            tool = ContextAnalyzerTool(
                project_dir=str(project_dir),
                docs_dir=str(custom_docs),
                max_file_size=custom_max_size,
                supported_extensions=custom_extensions
            )

            assert str(tool.docs_dir) == str(custom_docs)
            assert tool.max_file_size == custom_max_size
            assert tool.supported_extensions == custom_extensions

    def test_analyze_project_structure_method_signature(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –º–µ—Ç–æ–¥–∞ analyze_project_structure"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool
        import inspect

        sig = inspect.signature(ContextAnalyzerTool.analyze_project_structure)
        expected_params = ['self']

        actual_params = list(sig.parameters.keys())
        assert actual_params == expected_params

    def test_analyze_project_structure_return_type(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è analyze_project_structure"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.analyze_project_structure()

            assert isinstance(result, str)
            assert "üèóÔ∏è –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞" in result

    def test_find_file_dependencies_method_signature(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –º–µ—Ç–æ–¥–∞ find_file_dependencies"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool
        import inspect

        sig = inspect.signature(ContextAnalyzerTool.find_file_dependencies)
        expected_params = ['self', 'file_path']

        actual_params = list(sig.parameters.keys())
        assert actual_params == expected_params

        assert sig.parameters['file_path'].annotation == str

    def test_get_task_context_method_signature(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –º–µ—Ç–æ–¥–∞ get_task_context"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool
        import inspect

        sig = inspect.signature(ContextAnalyzerTool.get_task_context)
        expected_params = ['self', 'task_description']

        actual_params = list(sig.parameters.keys())
        assert actual_params == expected_params

        assert sig.parameters['task_description'].annotation == str

    def test_analyze_component_method_signature(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –º–µ—Ç–æ–¥–∞ analyze_component"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool
        import inspect

        sig = inspect.signature(ContextAnalyzerTool.analyze_component)
        expected_params = ['self', 'component_path']

        actual_params = list(sig.parameters.keys())
        assert actual_params == expected_params

        assert sig.parameters['component_path'].annotation == str

    def test_find_related_files_method_signature(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –º–µ—Ç–æ–¥–∞ find_related_files"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool
        import inspect

        sig = inspect.signature(ContextAnalyzerTool.find_related_files)
        expected_params = ['self', 'query']

        actual_params = list(sig.parameters.keys())
        assert actual_params == expected_params

        assert sig.parameters['query'].annotation == str

    def test_run_method_actions(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –≤ –º–µ—Ç–æ–¥–µ _run"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
            actions = ['analyze_project', 'find_dependencies', 'get_context',
                      'analyze_component', 'find_related_files']

            for action in actions:
                # –í—ã–∑—ã–≤–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                if action == 'analyze_project':
                    result = tool._run(action)
                else:
                    result = tool._run(action, **{f"{action.split('_')[1]}_param": "test"})

                assert isinstance(result, str)

    def test_run_method_unknown_action(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –≤ _run"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool._run("unknown_action")

            assert isinstance(result, str)
            assert "Unknown action" in result

    def test_file_dependencies_python_analysis(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Python —Ñ–∞–π–ª–æ–≤"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π Python —Ñ–∞–π–ª —Å –∏–º–ø–æ—Ä—Ç–∞–º–∏
            test_file = project_dir / "test_module.py"
            test_file.write_text("""
import os
import sys
from pathlib import Path
from typing import List, Dict
""")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.find_file_dependencies("test_module.py")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö
            assert isinstance(result, str)
            assert "test_module.py" in result

    def test_file_dependencies_markdown_analysis(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Markdown —Ñ–∞–π–ª–æ–≤"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π MD —Ñ–∞–π–ª —Å–æ —Å—Å—ã–ª–∫–∞–º–∏
            test_file = project_dir / "test.md"
            test_file.write_text("""
# Test Document

See [API docs](api.md) for details.
Also check [utils](utils.py) module.

Related: [config](config.yaml)
""")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.find_file_dependencies("test.md")

            assert isinstance(result, str)
            assert "test.md" in result

    def test_get_task_context_structure(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á–∏"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
            docs_dir = project_dir / "docs"
            docs_dir.mkdir()
            (docs_dir / "api.md").write_text("# API Documentation\nThis is about API development")
            (docs_dir / "guide.md").write_text("# User Guide\nHow to use the system")

            src_dir = project_dir / "src"
            src_dir.mkdir()
            (src_dir / "api.py").write_text("# API implementation\ndef get_data():\n    pass")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.get_task_context("—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å API")

            assert isinstance(result, str)
            assert "üìã –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–¥–∞—á–∏" in result

    def test_analyze_component_file(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞-—Ñ–∞–π–ª–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            test_file = project_dir / "test.py"
            test_content = "# Test Python file\ndef hello():\n    return 'world'"
            test_file.write_text(test_content)

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.analyze_component("test.py")

            assert isinstance(result, str)
            assert "üîç –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞" in result
            assert "test.py" in result
            assert "–¢–∏–ø:" in result and "file" in result

    def test_analyze_component_directory(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞-–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —Ñ–∞–π–ª–∞–º–∏
            test_dir = project_dir / "test_package"
            test_dir.mkdir()

            (test_dir / "__init__.py").write_text("")
            (test_dir / "module1.py").write_text("# Module 1")
            (test_dir / "module2.py").write_text("# Module 2")
            (test_dir / "README.md").write_text("# Package docs")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.analyze_component("test_package")

            assert isinstance(result, str)
            assert "üîç –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞" in result
            assert "test_package" in result
            assert "–¢–∏–ø:" in result and "directory" in result
            assert "–§–∞–π–ª–æ–≤:" in result

    def test_find_related_files_structure(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
            docs_dir = project_dir / "docs"
            docs_dir.mkdir()
            (docs_dir / "search.md").write_text("# Search functionality\nHow to implement search")

            src_dir = project_dir / "src"
            src_dir.mkdir()
            (src_dir / "search.py").write_text("# Search implementation\ndef find():\n    pass")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.find_related_files("search")

            assert isinstance(result, str)
            assert "üìÅ –§–∞–π–ª—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∑–∞–ø—Ä–æ—Å–æ–º" in result


class TestContextAnalyzerToolFormats:
    """–¢–µ—Å—Ç—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤"""

    def test_supported_file_types(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤
            test_files = {
                "test.md": "# Markdown file",
                "test.txt": "Plain text file",
                "test.py": "# Python file",
                "test.json": '{"key": "value"}',
                "test.yaml": "key: value",
                "test.yml": "key: value"
            }

            for filename, content in test_files.items():
                (project_dir / filename).write_text(content)

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
            for filename in test_files.keys():
                result = tool.analyze_component(filename)
                assert isinstance(result, str)
                assert filename in result

    def test_file_size_limits(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –Ω–∞ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–æ–≤"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å —Ä–∞–∑–º–µ—Ä–æ–º –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞
            large_file = project_dir / "large.py"
            large_content = "# Large file with more content to exceed size limit\n" * 200000  # –î–µ–ª–∞–µ–º —Ñ–∞–π–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞
            large_file.write_text(large_content)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ 1MB)
            file_size = large_file.stat().st_size
            assert file_size > 1000000, f"File size {file_size} is not greater than 1MB limit"
            assert file_size > 2000000, f"File size {file_size} should be much larger than 1MB for reliable testing"

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ü–æ–ø—ã—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –ø–æ–∏—Å–∫–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            result = tool.find_file_dependencies("large.py")

            # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–º —Ñ–∞–π–ª–µ –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å gracefully
            assert isinstance(result, str)

    def test_cache_initialization(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫—ç—à–µ–π"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫—ç—à–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
            assert hasattr(tool, '_analysis_cache')
            assert hasattr(tool, '_dependency_cache')

            assert isinstance(tool._analysis_cache, dict)
            assert isinstance(tool._dependency_cache, dict)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫—ç—à–∏ –ø—É—Å—Ç—ã–µ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            assert len(tool._analysis_cache) == 0
            assert len(tool._dependency_cache) == 0

    def test_normalize_unicode_text_function(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ normalize_unicode_text"""
        from src.tools.context_analyzer_tool import normalize_unicode_text

        # –¢–µ—Å—Ç —Å –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        assert normalize_unicode_text("Hello World") == "hello world"

        # –¢–µ—Å—Ç —Å Unicode —Å–∏–º–≤–æ–ª–∞–º–∏
        result = normalize_unicode_text("–¢–µ—Å—Ç na√Øve r√©sum√©")
        assert "—Ç–µ—Å—Ç" in result
        assert "naive" in result  # –±–µ–∑ –¥–∏–∞–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–∫–æ–≤
        assert "resume" in result  # –±–µ–∑ –¥–∏–∞–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–∫–æ–≤

        # –¢–µ—Å—Ç —Å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π
        assert normalize_unicode_text("") == ""

        # –¢–µ—Å—Ç —Å None
        assert normalize_unicode_text(None) == ""


class TestContextAnalyzerToolErrorHandling:
    """–¢–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ ContextAnalyzerTool"""

    def test_context_analyzer_with_nonexistent_project_dir(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π –ø—Ä–æ–µ–∫—Ç–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –î–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞—Ç—å—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫, –Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º
        tool = ContextAnalyzerTool(project_dir="/nonexistent/path")

        assert tool is not None
        result = tool.analyze_project_structure()
        assert isinstance(result, str)

    def test_context_analyzer_find_dependencies_nonexistent_file(self):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.find_file_dependencies("nonexistent_file.py")

            assert isinstance(result, str)
            assert "–Ω–µ –Ω–∞–π–¥–µ–Ω" in result or "not found" in result

    def test_context_analyzer_analyze_component_nonexistent(self):
        """–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.analyze_component("nonexistent_component")

            assert isinstance(result, str)
            assert "–Ω–µ –Ω–∞–π–¥–µ–Ω" in result or "not found" in result

    def test_context_analyzer_with_binary_file(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –±–∏–Ω–∞—Ä–Ω—ã–º —Ñ–∞–π–ª–æ–º"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º "–±–∏–Ω–∞—Ä–Ω—ã–π" —Ñ–∞–π–ª (—Å –Ω–µ—á–∏—Ç–∞–µ–º—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏)
            binary_file = project_dir / "binary.dat"
            with open(binary_file, 'wb') as f:
                f.write(bytes(range(256)))  # –í—Å–µ –±–∞–π—Ç—ã –æ—Ç 0 –¥–æ 255

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ê–Ω–∞–ª–∏–∑ –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª gracefully
            result = tool.analyze_component("binary.dat")
            assert isinstance(result, str)

    def test_context_analyzer_with_empty_directory(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –ø—É—Å—Ç–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.analyze_project_structure()

            assert isinstance(result, str)
            assert "–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞" in result

    def test_context_analyzer_with_nested_directories(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –≥–ª—É–±–æ–∫–æ –≤–ª–æ–∂–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º –≥–ª—É–±–æ–∫–æ –≤–ª–æ–∂–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            deep_path = project_dir
            for i in range(10):  # 10 —É—Ä–æ–≤–Ω–µ–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
                deep_path = deep_path / f"level_{i}"
                deep_path.mkdir()
                (deep_path / f"file_{i}.py").write_text(f"# Level {i} file")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.analyze_project_structure()

            assert isinstance(result, str)
            # –î–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–µ–∑ –ø—Ä–æ–±–ª–µ–º —Å –≥–ª—É–±–∏–Ω–æ–π

    def test_context_analyzer_get_task_context_empty_query(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á–∏ —Å –ø—É—Å—Ç—ã–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool
        import pytest

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            # –§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            with pytest.raises(ValueError, match="task_description must be a non-empty string"):
                tool.get_task_context("")

    def test_context_analyzer_find_related_files_empty_query(self):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å –ø—É—Å—Ç—ã–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.find_related_files("")

            assert isinstance(result, str)
            # –î–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å gracefully

    def test_context_analyzer_with_special_characters_in_paths(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ –≤ –ø—É—Ç—è—Ö"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã —Å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ –≤ –∏–º–µ–Ω–∞—Ö
            special_files = [
                "file with spaces.py",
                "file-with-dashes.py",
                "file_with_underscores.py",
                "file(1).py",
                "file[1].py"
            ]

            for filename in special_files:
                (project_dir / filename).write_text("# Test file")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            result = tool.analyze_project_structure()
            assert isinstance(result, str)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            for filename in special_files:
                result = tool.analyze_component(filename)
                assert isinstance(result, str)
                assert filename in result