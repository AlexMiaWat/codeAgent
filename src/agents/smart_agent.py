"""
Smart Agent - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∞–≥–µ–Ω—Ç–∞ —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
"""

from pathlib import Path
from typing import Optional, List
from crewai import Agent

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
from ..tools import LearningTool, ContextAnalyzerTool, is_docker_available

# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
__all__ = ['create_smart_agent', 'is_docker_available']

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º LLM –æ–±–µ—Ä—Ç–∫—É –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLMManager
try:
    from ..llm.crewai_llm_wrapper import create_llm_for_crewai
    LLM_WRAPPER_AVAILABLE = True
except ImportError:
    LLM_WRAPPER_AVAILABLE = False
    create_llm_for_crewai = None


def create_smart_agent(
    project_dir: Path,
    docs_dir: Optional[Path] = None,
    experience_dir: str = "smart_experience",
    role: str = "Smart Project Executor Agent",
    goal: str = "Execute complex tasks with enhanced intelligence, learning from previous executions",
    backstory: Optional[str] = None,
    allow_code_execution: bool = True,
    use_docker: bool = True,  # Simplified: True = use Docker if available, False = don't use
    verbose: bool = True,
    use_llm: bool = True,  # Simplified: True = use LLM if available, False = tool-only mode
    llm_config_path: str = "config/llm_settings.yaml",
    max_experience_tasks: int = 1000
) -> Agent:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ smart –∞–≥–µ–Ω—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏

    Args:
        project_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        docs_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        experience_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–ø—ã—Ç–∞
        role: –†–æ–ª—å –∞–≥–µ–Ω—Ç–∞
        goal: –¶–µ–ª—å –∞–≥–µ–Ω—Ç–∞
        backstory: –ò—Å—Ç–æ—Ä–∏—è/–∫–æ–Ω—Ç–µ–∫—Å—Ç –∞–≥–µ–Ω—Ç–∞
        allow_code_execution: –†–∞–∑—Ä–µ—à–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–¥–∞
        use_docker: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Docker –¥–ª—è code execution –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        verbose: –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
        use_llm: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        llm_config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM
        max_experience_tasks: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –≤ –æ–ø—ã—Ç–µ

    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π smart –∞–≥–µ–Ω—Ç CrewAI
    """

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    import logging
    logger = logging.getLogger(__name__)

    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    tools = []

    # Simplified Docker handling
    docker_available = False
    if allow_code_execution and use_docker:
        try:
            docker_available = is_docker_available()
            if docker_available:
                try:
                    from crewai_tools import CodeInterpreterTool
                    code_tool = CodeInterpreterTool()
                    tools.append(code_tool)
                    logger.info("CodeInterpreterTool added successfully")
                except Exception as e:
                    logger.warning(f"CodeInterpreterTool failed: {e}")
                    logger.info("‚ö†Ô∏è  Operating in limited mode: code execution disabled")
                    docker_available = False
            else:
                logger.info("Docker not available - code execution disabled")
        except Exception as e:
            logger.warning(f"Docker check failed: {e}")
            docker_available = False

    # –î–æ–±–∞–≤–ª—è–µ–º smart –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã)
    try:
        # LearningTool –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–¥–∞—á–∞—Ö
        learning_tool = LearningTool(
            experience_dir=str(project_dir / experience_dir),
            max_experience_tasks=max_experience_tasks
        )
        tools.append(learning_tool)

        # ContextAnalyzerTool –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞
        context_tool = ContextAnalyzerTool(
            project_dir=str(project_dir),
            docs_dir=str(docs_dir) if docs_dir else "docs"
        )
        tools.append(context_tool)

    except Exception as e:
        logger.error(f"Failed to initialize smart tools: {e}")
        raise  # Smart tools are critical, fail if they can't be initialized

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM
    import os

    llm_kwargs = {}
    llm_available = False

    if use_llm:
        # Try to use LLM if LLM_WRAPPER_AVAILABLE
        if LLM_WRAPPER_AVAILABLE:
            try:
                llm_kwargs['llm'] = create_llm_for_crewai(
                    config_path=llm_config_path,
                    use_fastest=True,
                    use_parallel=False
                )
                llm_available = True
                logger.info("LLM configured successfully")
            except Exception as e:
                logger.warning(f"LLM configuration failed: {e}")
                logger.info("üí° Tip: Check LLM configuration in config/llm_settings.yaml")

        # Fallback to OpenRouter if available and LLM wrapper failed
        if not llm_available and os.getenv('OPENROUTER_API_KEY'):
            try:
                from crewai.llm import LLM
                llm_kwargs['llm'] = LLM(
                    model="grok",
                    api_key=os.getenv('OPENROUTER_API_KEY'),
                    base_url="https://openrouter.ai/api/v1"
                )
                llm_available = True
                logger.info("Using OpenRouter fallback")
            except Exception as e:
                logger.warning(f"OpenRouter fallback failed: {e}")
                logger.info("üí° Tip: Verify OPENROUTER_API_KEY is set correctly")

    # If no LLM available, operate in tool-only mode
    if not llm_available:
        logger.info("Operating in tool-only mode (no LLM available)")
        llm_kwargs.clear()

    # Configure backstory if not provided
    if backstory is None:
        code_status = "with code execution" if (allow_code_execution and docker_available) else "without code execution"
        llm_status = "with LLM support" if llm_available else "in tool-only mode"

        backstory = f"""You are a smart agent that learns from task execution history and analyzes project context.
You use LearningTool and ContextAnalyzerTool to improve task execution quality.
You store experience data to provide better recommendations for similar tasks.
Operating {code_status} and {llm_status}.
"""

    # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
    if llm_available:
        agent = Agent(
            role=role,
            goal=goal,
            backstory=backstory,
            allow_code_execution=allow_code_execution and docker_available,
            verbose=verbose,
            tools=tools,
            **llm_kwargs,
            max_iter=30,
            memory=True,
        )
    else:
        agent = Agent(
            role=role,
            goal=goal,
            backstory=backstory,
            allow_code_execution=allow_code_execution and docker_available,
            verbose=verbose,
            tools=tools,
            llm=None,  # Explicitly disable LLM
            max_iter=30,
            memory=False,
        )

    # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å
    tool_names = [tool.__class__.__name__ if hasattr(tool, '__class__') else str(type(tool)) for tool in tools]
    logger.info(f"SmartAgent created with {len(tools)} tools: {', '.join(tool_names)}")
    logger.info(f"Docker: {'available' if docker_available else 'not available'}")
    logger.info(f"LLM: {'available' if llm_available else 'not available'}")

    # User-visible status notification
    capabilities = []
    limitations = []

    if docker_available:
        capabilities.append("code execution")
    else:
        limitations.append("no code execution")

    if llm_available:
        capabilities.append("LLM support")
    else:
        limitations.append("tool-only mode")

    if capabilities:
        logger.info(f"‚úÖ Smart Agent ready with: {', '.join(capabilities)}")
    if limitations:
        logger.warning(f"‚ö†Ô∏è  Limited functionality: {', '.join(limitations)}")

    return agent