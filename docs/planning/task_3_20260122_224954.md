# Планирование задачи #3: Умная LLM интеграция

## Обзор задачи

**Название:** Умная LLM интеграция
**Приоритет:** Высокий
**Сложность:** Высокая
**Оценка времени:** 2-3 недели
**Зависимости:** LLMManager, архитектура агентов, система проверки качества

## Техническое описание

### Цель
Создать комплексную систему умной LLM интеграции для автоматической проверки выполненной работы, валидации результатов, анализа ошибок и адаптивного выбора инструментов. Система должна использовать передовые LLM возможности для повышения качества и надежности выполнения задач.

### Архитектурные компоненты

#### 1. LLM Utils (`src/llm/llm_utils.py`)
Базовые утилиты для работы с LLM:
- `extract_json_object()` - Безопасное извлечение JSON из ответов LLM
- `safe_llm_call()` - Защищенный вызов LLM с обработкой ошибок
- `batch_llm_process()` - Пакетная обработка запросов
- `llm_cache` - Кэширование ответов LLM

#### 2. Валидационные функции

##### `_verify_real_work_done_llm()`
**Назначение:** Проверка реального выполнения работы через LLM анализ
- **Режим:** best_of_two для повышения надежности
- **Формат:** JSON mode для структурированного вывода
- **Критерии проверки:**
  - Наличие конкретных изменений в коде
  - Создание новых файлов/функций
  - Обновление документации
  - Исправление багов с конкретными примерами

##### `_validate_task_result_llm()`
**Назначение:** Оценка качества и полноты результатов выполнения задачи
- **Метрики качества:**
  - completeness (полнота выполнения)
  - correctness (правильность реализации)
  - efficiency (эффективность решения)
  - maintainability (поддерживаемость кода)

##### `_filter_completed_tasks_llm()`
**Назначение:** Умная фильтрация выполненных задач с учетом зависимостей
- **Анализ зависимостей:** Проверка связанных задач
- **Контекстный анализ:** Учет влияния на другие компоненты
- **Статус валидации:** Подтверждение полного завершения

#### 3. Аналитические функции

##### `_analyze_error_llm()`
**Назначение:** Категоризация ошибок и предложение решений
- **Категории ошибок:**
  - syntax_errors (синтаксические ошибки)
  - logic_errors (логические ошибки)
  - dependency_issues (проблемы зависимостей)
  - configuration_errors (ошибки конфигурации)
- **Предлагаемые решения:** Автоматическая генерация fix-ов

##### `_should_use_cursor_llm()`
**Назначение:** Адаптивный выбор инструмента выполнения
- **Факторы выбора:**
  - Сложность задачи
  - Тип требуемых изменений
  - Доступность инструментов
  - Предыдущий опыт выполнения

##### `_generate_instruction_llm()`
**Назначение:** Генерация инструкций с учетом контекста
- **Контекстный анализ:** Учет истории проекта и зависимостей
- **Адаптивные шаблоны:** Динамическое создание инструкций
- **Оптимизация:** Учет специфики конкретной задачи

## Архитектурные решения

### 1. Интеграция с существующей архитектурой

#### Совместимость с LLMManager
- Использование существующего `LLMManager` для доступа к моделям
- Поддержка best_of_two стратегии для критических проверок
- Fallback механизмы при недоступности LLM

#### Интеграция с агентами CrewAI
```python
# Пример интеграции в агента
class SmartValidationAgent(Agent):
    def __init__(self):
        super().__init__(
            role="LLM Validation Specialist",
            goal="Validate task completion using advanced LLM analysis",
            tools=[
                verify_real_work_done_llm,
                validate_task_result_llm,
                analyze_error_llm
            ]
        )
```

#### Расширение архитектуры Status Manager
```python
# Новые поля статуса задачи
task_status = {
    "llm_validation": {
        "verified": bool,
        "quality_score": float,
        "recommendations": list,
        "error_analysis": dict
    }
}
```

### 2. Стратегия best_of_two для критических функций

#### Реализация для `_verify_real_work_done_llm`
```python
async def _verify_real_work_done_llm(task_context, work_result):
    # Параллельная оценка двумя моделями
    responses = await llm_manager.generate_parallel([
        create_verification_prompt(task_context, work_result),
        create_verification_prompt(task_context, work_result)
    ])

    # Оценка и выбор лучшего результата
    evaluation = await evaluate_responses(responses)

    return {
        "verified": evaluation.best_response.verified,
        "confidence": evaluation.confidence_score,
        "reasoning": evaluation.reasoning
    }
```

#### JSON Mode для структурированного вывода
```json
{
  "verification_result": {
    "work_done": true,
    "confidence": 0.95,
    "evidence": [
      "Created new function calculate_metrics()",
      "Updated documentation in README.md",
      "Added unit tests for new functionality"
    ],
    "issues": [],
    "recommendations": ["Consider adding integration tests"]
  }
}
```

### 3. Кэширование и оптимизация производительности

#### LRU кэш для LLM ответов
```python
from functools import lru_cache
import asyncio

class LLMCache:
    def __init__(self, max_size=100, ttl_hours=1):
        self.cache = {}
        self.max_size = max_size
        self.ttl = ttl_hours * 3600

    @lru_cache(maxsize=100)
    async def get_cached_response(self, prompt_hash):
        # Кэшированная логика
        pass
```

#### Батч-обработка для множественных проверок
```python
async def batch_validate_tasks(tasks):
    # Группировка задач по типам
    batches = group_tasks_by_type(tasks)

    # Параллельная обработка батчей
    results = await asyncio.gather(*[
        process_batch(batch) for batch in batches
    ])

    return flatten_results(results)
```

## План реализации

### Этап 1: Базовая инфраструктура (3-4 дня)
1. Создать `src/llm/llm_utils.py` с базовыми утилитами
2. Реализовать `extract_json_object()` и `safe_llm_call()`
3. Добавить базовое кэширование ответов

### Этап 2: Функции валидации (4-5 дней)
1. Реализовать `_verify_real_work_done_llm()` с best_of_two
2. Создать `_validate_task_result_llm()` с метриками качества
3. Разработать `_filter_completed_tasks_llm()` с анализом зависимостей

### Этап 3: Аналитические функции (4-5 дней)
1. Реализовать `_analyze_error_llm()` с категоризацией
2. Создать `_should_use_cursor_llm()` для выбора инструментов
3. Разработать `_generate_instruction_llm()` с контекстом

### Этап 4: Интеграция и оптимизация (3-4 дня)
1. Интегрировать функции в архитектуру агентов
2. Добавить метрики производительности
3. Реализовать батч-обработку и кэширование

### Этап 5: Тестирование и документирование (2-3 дня)
1. Написать интеграционные тесты
2. Создать документацию API
3. Протестировать в реальных сценариях

## Потенциальные риски и их митигация

### Риск 1: Перегрузка LLM API
**Вероятность:** Высокая
**Влияние:** Превышение лимитов, дополнительные расходы
**Митигация:**
- Внедрение LRU кэширования с TTL
- Ограничение частоты запросов
- Fallback на кэшированные результаты

### Риск 2: Несогласованность оценок best_of_two
**Вероятность:** Средняя
**Влияние:** Противоречивые результаты валидации
**Митигация:**
- Улучшенный алгоритм оценки ответов
- Весовые коэффициенты для разных критериев
- Ручная валидация критических случаев

### Риск 3: Сложность интеграции с существующей архитектурой
**Вероятность:** Средняя
**Влияние:** Задержки в разработке, регрессии
**Митигация:**
- Поэтапная интеграция с модульным тестированием
- Создание адаптеров для совместимости
- Рефакторинг архитектуры при необходимости

### Риск 4: Низкая точность LLM анализа
**Вероятность:** Высокая для начальной версии
**Влияние:** Ложные срабатывания валидации
**Митигация:**
- Итеративное улучшение промптов
- Калибровка на исторических данных
- Гибридная валидация (LLM + правила)

### Риск 5: Производительность системы
**Вероятность:** Средняя
**Влияние:** Замедление работы агента
**Митигация:**
- Асинхронная обработка запросов
- Оптимизация размера промптов
- Кэширование промежуточных результатов

## Критерии приемки

### Функциональные требования
- [ ] Все 7 функций реализованы и протестированы
- [ ] Best_of_two режим работает корректно
- [ ] JSON mode возвращает структурированные данные
- [ ] Кэширование уменьшает количество API вызовов на 60%
- [ ] Анализ ошибок категоризирует 90%+ случаев

### Нефункциональные требования
- [ ] Время отклика < 30 сек для типичных задач
- [ ] Точность валидации > 85% на тестовых данных
- [ ] Поддержка всех типов задач (code/docs/test/refactor)
- [ ] Совместимость с существующей архитектурой
- [ ] Полное покрытие тестами (80%+)

### Интеграционные требования
- [ ] Интеграция с StatusManager для сохранения результатов
- [ ] Поддержка в агентах CrewAI
- [ ] Экспорт метрик для мониторинга
- [ ] API для внешнего доступа к функциям

## Связь с другими задачами и компонентами

### Зависимости от других задач
- **Задача #1 (Система качества и гейтов):** Использует гейты качества для активации LLM валидации
- **Задача #2 (Умная LLM интеграция):** Текущая задача - является основой
- **Задача #7 (Мониторинг и наблюдаемость):** Предоставляет метрики для дашбордов

### Влияние на компоненты проекта
- **LLMManager:** Расширение функциональности, новые стратегии
- **StatusManager:** Новые поля для результатов валидации
- **TodoManager:** Улучшенная фильтрация выполненных задач
- **Агенты CrewAI:** Новые инструменты для валидации

### Архитектурные изменения
- Добавление слоя "LLM Validation" в архитектуру
- Расширение интерфейсов агентов новыми методами
- Улучшение системы кэширования для LLM запросов

## Метрики успеха

### Технические метрики
- **Точность валидации:** > 85% корректных оценок
- **Производительность:** < 30 сек среднее время отклика
- **Надежность:** 99% успешных API вызовов с fallback
- **Эффективность кэширования:** 60%+ снижение API вызовов

### Бизнес-метрики
- **Качество выполнения задач:** Увеличение на 25%
- **Время на задачу:** Сокращение на 15%
- **Количество ошибок:** Снижение на 30%
- **Удовлетворенность:** Рост доверия к автоматизации

## Следующие шаги

1. **Анализ требований:** Детальный разбор спецификаций каждой функции
2. **Прототипирование:** Создание MVP основных функций
3. **Тестирование:** Валидация на реальных данных проекта
4. **Оптимизация:** Улучшение производительности и точности
5. **Документирование:** Создание полной технической документации

---
*Документация подготовлена для сессии 20260122_224954*
*Задача #3: Умная LLM интеграция*