# LLM Management in Code Agent

## Обзор

Code Agent использует `LLMManager` для интеллектуального управления языковыми моделями. Система ориентирована на использование **слабых и быстрых моделей** для координации задач, в то время как сложная интеллектуальная работа делегируется агентам Cursor (использующим мощные модели вроде GPT-4 или Claude Opus).

## Принципы работы

### 1. Разделение ответственности
- **Code Agent (Слабая LLM)**: Парсинг задач из TODO, выбор шаблонов инструкций, простые проверки результатов (наличие файла, контрольная фраза).
- **Cursor Agents (Мощная LLM)**: Глубокий анализ архитектуры, планирование, написание кода, рефакторинг, сложное тестирование.

### 2. "Слабые" модели
Для Code Agent рекомендуются модели уровня **GPT-3.5-turbo**, **Claude Haiku**, **Llama 3.1 8B**, или локальные модели **7B** (через Ollama). Они дешевы, быстры и отлично справляются с простыми инструкциями.

## Архитектура LLMManager

Менеджер моделей (`src/llm/llm_manager.py`) обеспечивает отказоустойчивость через систему ролей:

- **PRIMARY**: Основные рабочие модели.
- **DUPLICATE**: Резервные копии primary для параллельного выполнения.
- **RESERVE**: Модели на случай проблем с основными.
- **FALLBACK**: "Последний шанс" (например, бесплатные модели OpenRouter).

## Стратегии выполнения

### Fallback цепочка
Если основная модель возвращает ошибку или невалидный JSON, система автоматически пробует следующую модель в цепочке:
`PRIMARY` → `DUPLICATE` → `RESERVE` → `FALLBACK`.

### Параллельный режим (Best of Two)
Система может запускать две модели одновременно. Модель-оценщик анализирует оба ответа и выбирает лучший. Это повышает надежность без увеличения времени ожидания.

### JSON Mode
Гарантирует получение структурированного ответа (например, при оценке полезности задачи). Если формат нарушен, автоматически срабатывает fallback.

## Конфигурация

Настройки находятся в `config/llm_settings.yaml`. Основные провайдеры:
- **OpenRouter** (рекомендуется для агрегации множества моделей).
- **OpenAI**, **Anthropic**, **Google AI Studio**.
- **Ollama** (локально).

Подробнее о настройке ключей см. в [Руководстве по настройке](../guides/setup.md).
