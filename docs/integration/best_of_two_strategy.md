# Стратегия Best-of-Two: Детальное описание

## Обзор

Стратегия **Best-of-Two** - это механизм параллельного выполнения запросов к двум LLM моделям с последующим выбором лучшего ответа через оценку третьей моделью. Эта стратегия предназначена для повышения качества ответов за счет использования нескольких моделей и автоматизированного выбора оптимального результата.

## Архитектура

### Компоненты

1. **Исполнители (Executors)** - две модели, генерирующие ответы параллельно
2. **Оценщик (Evaluator)** - модель, оценивающая качество ответов
3. **Селектор (Selector)** - логика выбора лучшего ответа на основе оценок

### Конфигурация

```yaml
llm:
  strategy: best_of_two
  parallel:
    enabled: true
    models:
      - microsoft/wizardlm-2-8x22b      # Исполнитель 1
      - microsoft/phi-3-mini-128k-instruct  # Исполнитель 2
    evaluator_model: microsoft/wizardlm-2-8x22b  # Оценщик
    selection_criteria:
      - quality
      - relevance
      - completeness
      - efficiency
    parallel_timeout: 90        # Таймаут параллельного выполнения
    evaluation_timeout: 30      # Таймаут оценки
```

## Алгоритм работы

### Этап 1: Параллельное выполнение

```
Запрос → [Модель 1] → Ответ 1
       → [Модель 2] → Ответ 2
```

**Особенности:**
- Обе модели получают одинаковый запрос одновременно
- Выполнение в asyncio.gather для реальной параллельности
- Общий таймаут `parallel_timeout` (по умолчанию 90 сек)
- При таймауте fallback на single режим

### Этап 2: Валидация ответов

Для каждого ответа проверяется:
1. **Успешность вызова** - модель вернула ответ без ошибок
2. **Валидность контента** - ответ не пустой и содержит текст
3. **JSON mode валидация** (если применимо):
   - Попытка парсинга JSON
   - При неудаче модель добавляется в blacklist для JSON mode

### Этап 3: Оценка качества

Если есть валидные ответы от обеих моделей:

```
Для каждого ответа:
  Оценщик получает: "Оцени ответ на запрос..."
  Возвращает оценку 0-10 по шкале качества
```

**Критерии оценки:**
- **0-3**: Плохой ответ (нерелевантный, неполный, содержит ошибки)
- **4-6**: Средний ответ (частично релевантный, неполный)
- **7-9**: Хороший ответ (релевантный, полный, без грубых ошибок)
- **10**: Отличный ответ (полностью релевантный, полный, качественный, полезный)

### Этап 4: Выбор лучшего ответа

#### Основная логика выбора

```python
# 1. Если оценки сильно различаются (> 1.0)
best_response = max(responses, key=lambda r: r.score)

# 2. Если оценки близкие (≤ 1.0) - дополнительные критерии
if selection_criteria.includes('efficiency'):
    best_response = min(responses, key=lambda r: r.response_time)
elif selection_criteria.includes('completeness'):
    best_response = max(responses, key=lambda r: len(r.content))
```

#### Fallback сценарии

- **Нет оценщика**: возвращается первый успешный ответ
- **Ошибка оценки**: ответ получает оценку 3.0 (низкая)
- **Таймаут оценки**: ответ получает оценку 3.0
- **Одна модель работает**: возвращается её ответ без оценки

## Преимущества стратегии

### Качество ответов
- **Двойная экспертиза**: каждая задача решается двумя разными моделями
- **Автоматизированный выбор**: объективная оценка без субъективных факторов
- **Обучение на оценках**: система улучшается со временем

### Надежность
- **Резервирование**: если одна модель падает, используется другая
- **Валидация**: автоматическая проверка корректности ответов
- **Таймауты**: защита от зависаний

### Производительность
- **Параллельность**: общее время ≈ max(время_модели_1, время_модели_2)
- **Кеширование**: повторные запросы обслуживаются мгновенно
- **Оптимизация**: выбор быстрой модели при близком качестве

## Ограничения и компромиссы

### Производительность
- **Стоимость**: 3 вызова вместо 1 (2 исполнения + 1 оценка)
- **Время**: зависит от самой медленной модели
- **Ресурсы**: повышенное потребление API лимитов

### Качество оценки
- **Субъективность оценщика**: зависит от качества модели-оценщика
- **Шум в оценках**: близкие по качеству ответы могут оцениваться противоречиво
- **Сложность запросов**: оценка сложных технических ответов может быть неточной

## Практические рекомендации

### Выбор моделей

#### Исполнители (Executors)
- **Разные архитектуры**: комбинации разных семейств моделей
- **Баланс скорость/качество**: одна быстрая + одна качественная
- **Стабильность**: проверенные модели без частых сбоев

**Рекомендуемые пары:**
```
microsoft/wizardlm-2-8x22b + google/gemma-2-27b-it
microsoft/phi-3-mini-128k-instruct + anthropic/claude-3.5-sonnet
meta-llama/llama-3.2-3b-instruct + openai/gpt-4o-mini
```

#### Оценщик (Evaluator)
- **Стабильная модель**: должна давать consistent оценки
- **Хорошая инструкционная следование**: понимает критерии оценки
- **Быстрая**: не должна сильно увеличивать общее время

**Рекомендуемые оценщики:**
```
microsoft/wizardlm-2-8x22b    # Стабильный, качественный
anthropic/claude-3.5-sonnet   # Очень точный, но дорогой
microsoft/phi-3-mini-128k     # Быстрый и надежный
```

### Настройка таймаутов

```yaml
# Для быстрого отклика
parallel_timeout: 60   # 1 минута на генерацию
evaluation_timeout: 20 # 20 сек на оценку

# Для сложных задач
parallel_timeout: 180  # 3 минуты на генерацию
evaluation_timeout: 60 # 1 минута на оценку
```

### Критерии выбора

```yaml
selection_criteria:
  - quality        # Основной критерий
  - relevance      # Важность для конкретной задачи
  - efficiency     # Скорость ответа
  - completeness   # Полнота ответа
```

## Мониторинг и отладка

### Метрики для отслеживания

```
- Процент выбора первой модели
- Процент выбора второй модели
- Среднее время оценки
- Процент таймаутов
- Распределение оценок (гистограмма)
```

### Логирование

```
INFO: Selected best response from microsoft/wizardlm-2-8x22b (score: 8.5)
DEBUG: Response 1 from model1 scored: 7.2 (2.3s)
DEBUG: Response 2 from model2 scored: 8.5 (1.8s)
WARNING: Evaluation timeout for response 1
ERROR: Parallel generation failed, fallback to single
```

### Отладка проблем

#### Симптом: Всегда выбирается одна модель
**Возможные причины:**
- Оценщик смещен в сторону определенной модели
- Различия в качестве ответов слишком велики
- Проблемы с токенизацией/форматированием

#### Симптом: Высокий процент таймаутов
**Решения:**
- Увеличить `parallel_timeout`
- Выбрать более быстрые модели
- Оптимизировать промпт

#### Симптом: Низкие оценки качества
**Решения:**
- Проверить критерии оценки в промпте
- Выбрать более качественную модель-оценщик
- Улучшить инструкции для исполнителей

## Будущие улучшения

### Короткосрочные
- **Множественные оценщики**: несколько моделей для оценки с голосованием
- **Динамический выбор пар**: адаптация под тип задачи
- **Контекстная оценка**: учет специфики предметной области

### Долгосрочные
- **Обучение оценщика**: fine-tuning на парах ответов
- **Мета-оценка**: оценка качества работы оценщика
- **Цепочки моделей**: последовательное улучшение ответов

## Заключение

Best-of-two стратегия представляет собой сбалансированный подход к повышению качества LLM ответов через параллельное выполнение и автоматизированную оценку. Несмотря на повышенную стоимость, она обеспечивает:

- **Надежность**: резервирование и валидация
- **Качество**: двойная экспертиза и выбор лучшего
- **Адаптивность**: возможность настройки под конкретные нужды

Стратегия особенно эффективна для задач, где качество критичнее скорости, и где доступны несколько качественных моделей.