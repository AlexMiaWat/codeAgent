#!/usr/bin/env python3
"""
–ù–∞–≥—Ä—É–∑–æ—á–Ω—ã–µ —Ç–µ—Å—Ç—ã Smart Agent
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ–¥ –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π
"""

import sys
import tempfile
import shutil
import time
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from statistics import mean, median, stdev
import psutil
import gc

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


class LoadTestMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""

    def __init__(self):
        self.response_times = []
        self.memory_usage = []
        self.cpu_usage = []
        self.errors = 0
        self.start_time = time.time()

    def record_response_time(self, duration):
        self.response_times.append(duration)

    def record_memory_usage(self):
        process = psutil.Process()
        self.memory_usage.append(process.memory_info().rss / 1024 / 1024)  # MB

    def record_cpu_usage(self):
        self.cpu_usage.append(psutil.cpu_percent(interval=0.1))

    def record_error(self):
        self.errors += 1

    def get_summary(self):
        total_time = time.time() - self.start_time
        return {
            'total_time': total_time,
            'total_requests': len(self.response_times),
            'errors': self.errors,
            'success_rate': (len(self.response_times) - self.errors) / len(self.response_times) if self.response_times else 0,
            'avg_response_time': mean(self.response_times) if self.response_times else 0,
            'median_response_time': median(self.response_times) if self.response_times else 0,
            'min_response_time': min(self.response_times) if self.response_times else 0,
            'max_response_time': max(self.response_times) if self.response_times else 0,
            'response_time_stdev': stdev(self.response_times) if len(self.response_times) > 1 else 0,
            'avg_memory_usage': mean(self.memory_usage) if self.memory_usage else 0,
            'avg_cpu_usage': mean(self.cpu_usage) if self.cpu_usage else 0,
            'requests_per_second': len(self.response_times) / total_time if total_time > 0 else 0
        }


class SmartAgentLoadTester:
    """–ù–∞–≥—Ä—É–∑–æ—á–Ω—ã–π —Ç–µ—Å—Ç–µ—Ä Smart Agent"""

    def __init__(self, temp_dir=None):
        self.temp_dir = Path(temp_dir or tempfile.mkdtemp(prefix="smart_agent_load_test_"))
        self.experience_dir = self.temp_dir / "experience"
        self.project_dir = self.temp_dir / "project"
        self.metrics = LoadTestMetrics()

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        self._setup_test_project()

    def _setup_test_project(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞"""
        self.project_dir.mkdir(parents=True, exist_ok=True)

        # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ Python —Ñ–∞–π–ª–æ–≤
        for i in range(10):
            file_path = self.project_dir / f"module_{i}.py"
            content = f'''
"""Module {i} for load testing"""

import sys
import os
from pathlib import Path

class Class{i}:
    """Test class {i}"""

    def __init__(self, value):
        self.value = value

    def method_{i}(self):
        """Test method"""
        return f"result_{i}: {{self.value}}"

def function_{i}(param):
    """Test function {i}"""
    return param * {i}

CONSTANT_{i} = {i * 100}

# Some imports to test dependency analysis
import json
import datetime
'''
            file_path.write_text(content)

        # –°–æ–∑–¥–∞–µ–º requirements.txt
        (self.project_dir / "requirements.txt").write_text('''
pytest>=7.0.0
requests>=2.28.0
fastapi>=0.68.0
uvicorn>=0.15.0
''')

        # –°–æ–∑–¥–∞–µ–º README
        (self.project_dir / "README.md").write_text('''
# Load Test Project

This is a test project for Smart Agent load testing.

## Features

- Multiple Python modules
- Dependencies management
- Documentation
''')

    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)

    def load_test_learning_tool(self, num_tasks=1000, num_threads=10):
        """–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LearningTool"""
        print(f"üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LearningTool: {num_tasks} –∑–∞–¥–∞—á, {num_threads} –ø–æ—Ç–æ–∫–æ–≤")

        from src.tools.learning_tool import LearningTool

        tool = LearningTool(experience_dir=str(self.experience_dir))

        def save_task_worker(task_range):
            """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á"""
            for i in task_range:
                start_time = time.time()

                try:
                    tool._run("save_experience",
                                     task_id=f"load_task_{i:06d}",
                                     task_description=f"Load test task #{i} for performance testing",
                                     success=i % 10 != 0,  # 90% success rate
                                     execution_time=0.1 + (i % 100) * 0.01,
                                     patterns=[f"pattern_{(i % 5)}", "load_test", f"batch_{(i // 100)}"],
                                     notes=f"Detailed notes for task {i} with some additional context")

                    duration = time.time() - start_time
                    self.metrics.record_response_time(duration)
                    self.metrics.record_memory_usage()

                except Exception as e:
                    self.metrics.record_error()
                    print(f"‚ùå Error in task {i}: {e}")

        # –†–∞–∑–¥–µ–ª—è–µ–º –∑–∞–¥–∞—á–∏ –º–µ–∂–¥—É –ø–æ—Ç–æ–∫–∞–º–∏
        tasks_per_thread = num_tasks // num_threads
        task_ranges = []
        for t in range(num_threads):
            start = t * tasks_per_thread
            end = start + tasks_per_thread if t < num_threads - 1 else num_tasks
            task_ranges.append(range(start, end))

        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(save_task_worker, task_range) for task_range in task_ranges]
            for future in as_completed(futures):
                future.result()

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")

        search_queries = [
            "performance testing",
            "load test",
            "pattern_0",
            "batch_5",
            "–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å"
        ]

        for query in search_queries:
            start_time = time.time()
            try:
                tool._run("find_similar_tasks", query=query)
                duration = time.time() - start_time
                self.metrics.record_response_time(duration)
                self.metrics.record_memory_usage()
            except Exception as e:
                self.metrics.record_error()
                print(f"‚ùå Search error for '{query}': {e}")

    def load_test_context_analyzer(self, num_iterations=100, num_threads=5):
        """–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ContextAnalyzerTool"""
        print(f"üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ContextAnalyzerTool: {num_iterations} –∏—Ç–µ—Ä–∞—Ü–∏–π, {num_threads} –ø–æ—Ç–æ–∫–æ–≤")

        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        tool = ContextAnalyzerTool(
            project_dir=str(self.project_dir),
            max_file_size=1024*1024  # 1MB
        )

        def analysis_worker(iterations):
            """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
            for i in iterations:
                self.metrics.record_memory_usage()

                # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞
                start_time = time.time()
                try:
                    tool._run("analyze_project")
                    duration = time.time() - start_time
                    self.metrics.record_response_time(duration)
                except Exception as e:
                    self.metrics.record_error()
                    print(f"‚ùå Project analysis error {i}: {e}")

                # –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                file_path = f"module_{(i % 10)}.py"
                start_time = time.time()
                try:
                    tool._run("analyze_dependencies", file_path=file_path)
                    duration = time.time() - start_time
                    self.metrics.record_response_time(duration)
                except Exception as e:
                    self.metrics.record_error()
                    print(f"‚ùå Dependency analysis error {i}: {e}")

                # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                start_time = time.time()
                try:
                    tool._run("analyze_file", file_path=file_path)
                    duration = time.time() - start_time
                    self.metrics.record_response_time(duration)
                except Exception as e:
                    self.metrics.record_error()
                    print(f"‚ùå File analysis error {i}: {e}")

        # –†–∞–∑–¥–µ–ª—è–µ–º –∏—Ç–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É –ø–æ—Ç–æ–∫–∞–º–∏
        iterations_per_thread = num_iterations // num_threads
        iteration_ranges = []
        for t in range(num_threads):
            start = t * iterations_per_thread
            end = start + iterations_per_thread if t < num_threads - 1 else num_iterations
            iteration_ranges.append(range(start, end))

        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(analysis_worker, it_range) for it_range in iteration_ranges]
            for future in as_completed(futures):
                future.result()

    def load_test_combined_workflow(self, num_workflows=50, num_threads=5):
        """–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"""
        print(f"üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ workflow: {num_workflows} workflows, {num_threads} –ø–æ—Ç–æ–∫–æ–≤")

        from src.tools.learning_tool import LearningTool
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        learning_tool = LearningTool(experience_dir=str(self.experience_dir))
        context_tool = ContextAnalyzerTool(project_dir=str(self.project_dir))

        def workflow_worker(workflow_range):
            """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ workflow"""
            for i in workflow_range:
                workflow_start = time.time()

                try:
                    # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
                    context_tool._run("analyze_project")

                    # –®–∞–≥ 2: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–ø—ã—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
                    learning_tool._run("save_experience",
                                     task_id=f"workflow_analysis_{i:04d}",
                                     task_description=f"Analysis workflow #{i}",
                                     success=True,
                                     execution_time=time.time() - workflow_start,
                                     patterns=["analysis", "workflow", f"thread_{threading.current_thread().ident % 5}"],
                                     notes="Combined workflow analysis")

                    # –®–∞–≥ 3: –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á
                    learning_tool._run("find_similar_tasks",
                                                     query="analysis workflow")

                    # –®–∞–≥ 4: –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
                    context_tool._run("analyze_dependencies",
                                                 file_path="module_0.py")

                    # –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–ø—ã—Ç–∞
                    total_time = time.time() - workflow_start
                    learning_tool._run("save_experience",
                                     task_id=f"workflow_complete_{i:04d}",
                                     task_description=f"Complete workflow #{i}",
                                     success=True,
                                     execution_time=total_time,
                                     patterns=["complete", "workflow", "integration"],
                                     notes=f"Full workflow completed in {total_time:.2f}s")

                    self.metrics.record_response_time(total_time)
                    self.metrics.record_memory_usage()

                except Exception as e:
                    self.metrics.record_error()
                    print(f"‚ùå Workflow {i} error: {e}")

        # –†–∞–∑–¥–µ–ª—è–µ–º workflows –º–µ–∂–¥—É –ø–æ—Ç–æ–∫–∞–º–∏
        workflows_per_thread = num_workflows // num_threads
        workflow_ranges = []
        for t in range(num_threads):
            start = t * workflows_per_thread
            end = start + workflows_per_thread if t < num_threads - 1 else num_workflows
            workflow_ranges.append(range(start, end))

        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(workflow_worker, wf_range) for wf_range in workflow_ranges]
            for future in as_completed(futures):
                future.result()

    def run_full_load_test(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –Ω–∞–≥—Ä—É–∑–æ—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        print("üöÄ –ù–ê–ß–ê–õ–û –ù–ê–ì–†–£–ó–û–ß–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø SMART AGENT")
        print("="*70)

        test_configs = [
            ("LearningTool Load Test", lambda: self.load_test_learning_tool(500, 5)),
            ("ContextAnalyzer Load Test", lambda: self.load_test_context_analyzer(50, 3)),
            ("Combined Workflow Load Test", lambda: self.load_test_combined_workflow(25, 3)),
        ]

        all_summaries = []

        for test_name, test_func in test_configs:
            print(f"\nüî• –ó–ê–ü–£–°–ö: {test_name}")
            print("-" * 50)

            # –°–±—Ä–æ—Å –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞
            self.metrics = LoadTestMetrics()

            try:
                test_func()
                summary = self.metrics.get_summary()
                all_summaries.append((test_name, summary))

                print(f"‚úÖ {test_name} –∑–∞–≤–µ—Ä—à–µ–Ω")
                self._print_test_summary(summary)

            except Exception as e:
                print(f"‚ùå {test_name} –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}")
                all_summaries.append((test_name, {'error': str(e)}))

            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
            gc.collect()
            time.sleep(1)

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        print("\n" + "="*70)
        print("üìä –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ù–ê–ì–†–£–ó–û–ß–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        print("="*70)

        for test_name, summary in all_summaries:
            print(f"\nüîç {test_name}:")
            if 'error' in summary:
                print(f"  ‚ùå –û–®–ò–ë–ö–ê: {summary['error']}")
            else:
                print(".2f")
                print(".2f")
                print(".1f")
                print(".1f")

        return all_summaries

    def _print_test_summary(self, summary):
        """–í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Ç–µ—Å—Ç—É"""
        print("\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"  ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {summary['total_time']:.2f}—Å")
        print(f"  üìä –ó–∞–ø—Ä–æ—Å–æ–≤: {summary['total_requests']}")
        print(f"  üéØ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {summary['success_rate']:.1f}%")
        print(f"  ‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {summary['avg_response_time']:.2f}—Å")
        print(f"  üíæ –°—Ä–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {summary['avg_memory_usage']:.1f}MB")
        print(f"  üîÑ –ó–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É: {summary['requests_per_second']:.3f}")
        if summary['errors'] > 0:
            print(f"  ‚ùå –û—à–∏–±–æ–∫: {summary['errors']}")
            print(".1f")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("‚ö° SMART AGENT LOAD TESTING")
    print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π\n")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ psutil
    try:
        import psutil
    except ImportError:
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ psutil: pip install psutil")
        return 1

    tester = None
    try:
        tester = SmartAgentLoadTester()

        # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
        results = tester.run_full_load_test()

        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        total_errors = sum(1 for _, summary in results if 'error' in summary or summary.get('errors', 0) > 0)

        if total_errors == 0:
            print("\nüéâ –í–°–ï –ù–ê–ì–†–£–ó–û–ß–ù–´–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
            print("Smart Agent –≥–æ—Ç–æ–≤ –∫ –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–µ.")
            return 0
        else:
            print(f"\n‚ö†Ô∏è  –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´ –í {total_errors} –¢–ï–°–¢–ê–•")
            print("–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.")
            return 1

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 130
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return 1
    finally:
        if tester:
            tester.cleanup()


if __name__ == "__main__":
    sys.exit(main())