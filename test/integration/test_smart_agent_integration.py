#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã Smart Agent
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –Ω–∞–≥—Ä—É–∑–æ—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
"""

import sys
import tempfile
import shutil
import time
from pathlib import Path

import json
from concurrent.futures import ThreadPoolExecutor, as_completed


class TestSmartAgentIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã Smart Agent"""

    def setup_method(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ç–µ—Å—Ç–æ–º"""
        self.temp_dir = Path(tempfile.mkdtemp(prefix="smart_agent_test_"))
        self.experience_dir = self.temp_dir / "experience"
        self.project_dir = self.temp_dir / "project"

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        self.project_dir.mkdir()
        (self.project_dir / "main.py").write_text("""
import os
from pathlib import Path
from utils import helper_function

def main():
    print("Hello from test project")
    helper_function()

if __name__ == "__main__":
    main()
""")

        (self.project_dir / "requirements.txt").write_text("""
pytest>=7.0.0
requests>=2.28.0
""")

        (self.project_dir / "utils.py").write_text("""
def helper_function():
    return "helper result"

class UtilityClass:
    def __init__(self, value):
        self.value = value

    def process(self):
        return f"processed: {self.value}"
""")

    def teardown_method(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞"""
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)

    def test_learning_tool_real_data_integration(self):
        """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ LearningTool —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        from src.tools.learning_tool import LearningTool

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        tool = LearningTool(experience_dir=str(self.experience_dir))

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á –æ–ø—ã—Ç–∞
        tasks_data = [
            {
                "task_id": "task_001",
                "description": "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏",
                "success": True,
                "execution_time": 15.5,
                "patterns": ["testing", "configuration"],
                "notes": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª pytest.ini –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
            },
            {
                "task_id": "task_002",
                "description": "–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –≤ requirements.txt",
                "success": True,
                "execution_time": 8.2,
                "patterns": ["dependencies", "requirements"],
                "notes": "–û–±–Ω–æ–≤–∏–ª –≤–µ—Ä—Å–∏–∏ –ø–∞–∫–µ—Ç–æ–≤"
            },
            {
                "task_id": "task_003",
                "description": "–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞",
                "success": True,
                "execution_time": 22.1,
                "patterns": ["project_structure", "organization"],
                "notes": "–°–æ–∑–¥–∞–ª —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É Python –ø—Ä–æ–µ–∫—Ç–∞"
            }
        ]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—ã—Ç
        for task in tasks_data:
            result = tool.save_task_experience(
                task_id=task["task_id"],
                task_description=task["description"],
                success=task["success"],
                execution_time=task["execution_time"],
                patterns=task["patterns"],
                notes=task["notes"]
            )
            assert "—Å–æ—Ö—Ä–∞–Ω–µ–Ω" in result.lower()

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á
        similar_tasks = tool.find_similar_tasks(query="–ù–∞—Å—Ç—Ä–æ–π–∫–∞ pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
        assert "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏" in similar_tasks  # –ù–∞—à–ª–∏ –∑–∞–¥–∞—á—É –ø–æ —Ç–æ—á–Ω–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é
        assert "–ù–∞–π–¥–µ–Ω–æ 1 –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á" in similar_tasks  # –ù–∞—à–ª–∏ —Ä–æ–≤–Ω–æ –æ–¥–Ω—É –∑–∞–¥–∞—á—É

    def test_context_analyzer_real_project_integration(self):
        """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ ContextAnalyzerTool —Å —Ä–µ–∞–ª—å–Ω—ã–º –ø—Ä–æ–µ–∫—Ç–æ–º"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        tool = ContextAnalyzerTool(
            project_dir=str(self.project_dir),
            supported_extensions=[".py", ".txt"]
        )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        analysis_result = tool.analyze_project_structure()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        assert ".py: 2 —Ñ–∞–π–ª–æ–≤" in analysis_result  # main.py –∏ utils.py
        assert ".txt: 1 —Ñ–∞–π–ª–æ–≤" in analysis_result  # requirements.txt
        assert "–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞" in analysis_result

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        dependency_result = tool.find_file_dependencies(file_path="main.py")

        # main.py –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑ utils, –ø–æ—ç—Ç–æ–º—É –¥–æ–ª–∂–Ω–∞ –Ω–∞–π—Ç–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å
        assert "utils.py" in dependency_result or "utils/__init__.py" in dependency_result

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        file_analysis = tool.analyze_component(component_path="utils.py")

        assert "utils.py" in file_analysis
        assert "file" in file_analysis  # –¢–∏–ø —Ñ–∞–π–ª–∞
        assert ".py" in file_analysis  # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        assert "–†–∞–∑–º–µ—Ä:" in file_analysis  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞

    def test_tools_interaction_workflow(self):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        from src.tools.learning_tool import LearningTool
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        learning_tool = LearningTool(experience_dir=str(self.experience_dir))
        context_tool = ContextAnalyzerTool(project_dir=str(self.project_dir))

        # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç
        project_context = context_tool.analyze_project_structure()
        assert len(project_context) > 0

        # –®–∞–≥ 2: –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—ã—Ç –∞–Ω–∞–ª–∏–∑–∞
        learning_tool.save_task_experience(
            task_id="analysis_workflow_001",
            task_description="–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏",
            success=True,
            execution_time=5.2,
            patterns=["analysis", "project_structure"],
            notes="–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ Python –ø—Ä–æ–µ–∫—Ç–∞"
        )

        # –®–∞–≥ 3: –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞
        similar = learning_tool.find_similar_tasks(query="–∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞")

        assert "–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏" in similar  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è

        # –®–∞–≥ 4: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        context_tool.find_file_dependencies(file_path="main.py")

        # –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
        learning_tool.save_task_experience(
            task_id="dependency_workflow_002",
            task_description="–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Python –º–æ–¥—É–ª—è",
            success=True,
            execution_time=3.1,
            patterns=["dependencies", "python_imports"],
            notes="–ù–∞–π–¥–µ–Ω—ã –∏–º–ø–æ—Ä—Ç—ã pathlib –∏ os"
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±–∞ –æ–ø—ã—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
        experience_file = self.experience_dir / "experience.json"
        assert experience_file.exists()

        with open(experience_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        assert len(data['tasks']) == 2
        assert "analysis_workflow_001" in [t['task_id'] for t in data['tasks']]
        assert "dependency_workflow_002" in [t['task_id'] for t in data['tasks']]

    def test_performance_under_load(self):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π"""
        from src.tools.learning_tool import LearningTool

        tool = LearningTool(experience_dir=str(self.experience_dir))

        # –î–æ–±–∞–≤–ª—è–µ–º –º–Ω–æ–≥–æ –∑–∞–¥–∞—á –æ–ø—ã—Ç–∞ (100 –∑–∞–¥–∞—á)
        start_time = time.time()

        for i in range(100):
            tool.save_task_experience(
                task_id=f"perf_task_{i:03d}",
                task_description=f"–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ #{i}",
                success=True,
                execution_time=1.0 + (i % 10) * 0.1,
                patterns=["performance", f"pattern_{i%5}"],
                notes=f"–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–º–µ—Ç–∫–∞ #{i}"
            )

        save_time = time.time() - start_time

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–∞–∑—É–º–Ω—ã–º)
        assert save_time < 10.0, f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ 100 –∑–∞–¥–∞—á –∑–∞–Ω—è–ª–æ {save_time:.2f}—Å"

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π
        search_start = time.time()
        results = tool.find_similar_tasks(query="–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

        search_time = time.time() - search_start

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–Ω—å—à–µ 2 —Å–µ–∫—É–Ω–¥)
        assert search_time < 2.0, f"–ü–æ–∏—Å–∫ –≤ 100 –∑–∞–¥–∞—á–∞—Ö –∑–∞–Ω—è–ª {search_time:.2f}—Å"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
        assert "–ù–∞–π–¥–µ–Ω–æ" in results and "–ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á" in results  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω—ã –∑–∞–¥–∞—á–∏
        assert "–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏" in results  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è

    def test_concurrent_access_safety(self):
        """–¢–µ—Å—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞"""
        from src.tools.learning_tool import LearningTool

        tool = LearningTool(experience_dir=str(self.experience_dir))

        def worker(worker_id):
            """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞"""
            for i in range(10):
                task_id = f"concurrent_task_{worker_id}_{i}"
                tool.save_task_experience(
                    task_id=task_id,
                    task_description=f"–ó–∞–¥–∞—á–∞ –æ—Ç worker {worker_id} #{i}",
                    success=True,
                    execution_time=0.5,
                    patterns=[f"worker_{worker_id}", "concurrent"],
                    notes=f"Concurrent test task {i}"
                )

                # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
                time.sleep(0.001 * (i % 3))

        # –ó–∞–ø—É—Å–∫–∞–µ–º 5 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(worker, i) for i in range(5)]
            for future in as_completed(futures):
                future.result()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–π

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
        experience_file = self.experience_dir / "experience.json"
        assert experience_file.exists()

        with open(experience_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π)
        assert len(data['tasks']) >= 3, f"–û–∂–∏–¥–∞–ª–æ—Å—å –º–∏–Ω–∏–º—É–º 3 –∑–∞–¥–∞—á–∏, –ø–æ–ª—É—á–µ–Ω–æ {len(data['tasks'])}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å task_id —Å—Ä–µ–¥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        task_ids = [t['task_id'] for t in data['tasks']]
        unique_task_ids = set(task_ids)
        assert len(unique_task_ids) == len(task_ids), "–ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã task_id"

    def test_error_handling_integration(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏"""
        from src.tools.learning_tool import LearningTool
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        learning_tool = LearningTool(experience_dir=str(self.experience_dir))
        context_tool = ContextAnalyzerTool(project_dir=str(self.project_dir))

        # –¢–µ—Å—Ç 1: –ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–ø—ã—Ç —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        try:
            learning_tool.save_task_experience(
                task_id="",  # –ü—É—Å—Ç–æ–π task_id
                task_description="–¢–µ—Å—Ç –æ—à–∏–±–∫–∏",
                success=True,
                execution_time=-1,  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
                patterns=[],
                notes=""
            )
            assert False, "–î–æ–ª–∂–Ω–æ –±—ã–ª–æ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ"
        except (ValueError, AssertionError):
            pass  # –û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ

        # –¢–µ—Å—Ç 2: –ü–æ–ø—ã—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        try:
            context_tool.analyze_component(component_path="nonexistent_file.py")
            # –≠—Ç–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, –∞ –≤–µ—Ä–Ω—É—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        except (FileNotFoundError, ValueError):
            pass  # –û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ

        # –¢–µ—Å—Ç 3: –ü–æ–∏—Å–∫ –≤ –ø—É—Å—Ç–æ–º –æ–ø—ã—Ç–µ
        results = learning_tool.find_similar_tasks(query="–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å")

        # –î–æ–ª–∂–Ω—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –Ω–æ –±–µ–∑ –æ—à–∏–±–∫–∏
        assert isinstance(results, str)
        assert len(results) >= 0

    def test_memory_management_integration(self):
        """–¢–µ—Å—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é –≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        big_file = self.project_dir / "big_file.py"
        big_content = "# –ë–æ–ª—å—à–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª\n" + "\n".join([
            f"def function_{i}():\n    return {i}\n"
            for i in range(1000)
        ])

        big_file.write_text(big_content)

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        tool = ContextAnalyzerTool(
            project_dir=str(self.project_dir),
            max_file_size=5000  # 5KB limit
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–∏–ø —Ñ–∞–π–ª–∞ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
        analysis = tool.analyze_project_structure()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Python —Ñ–∞–π–ª–æ–≤
        assert ".py" in analysis

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
        tool_unlimited = ContextAnalyzerTool(
            project_dir=str(self.project_dir),
            max_file_size=100000  # 100KB limit
        )

        # –¢–µ–ø–µ—Ä—å —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é
        analysis_unlimited = tool_unlimited.analyze_project_structure()
        assert ".py" in analysis_unlimited


def run_integration_tests():
    """–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ Smart Agent...")

    test_instance = TestSmartAgentIntegration()

    tests = [
        ("Real Data Integration", test_instance.test_learning_tool_real_data_integration),
        ("Real Project Integration", test_instance.test_context_analyzer_real_project_integration),
        ("Tools Workflow", test_instance.test_tools_interaction_workflow),
        ("Performance Under Load", test_instance.test_performance_under_load),
        ("Concurrent Access Safety", test_instance.test_concurrent_access_safety),
        ("Error Handling Integration", test_instance.test_error_handling_integration),
        ("Memory Management Integration", test_instance.test_memory_management_integration),
    ]

    results = []

    for test_name, test_func in tests:
        try:
            print(f"\nüîß –ó–∞–ø—É—Å–∫: {test_name}")
            test_instance.setup_method()
            test_func()
            test_instance.teardown_method()
            results.append((test_name, True))
            print(f"‚úÖ {test_name}: –ü–†–û–ô–î–ï–ù")
        except Exception as e:
            test_instance.teardown_method()
            results.append((test_name, False))
            print(f"‚ùå {test_name}: –ü–†–û–í–ê–õ–ï–ù - {e}")

    # –ò—Ç–æ–≥–∏
    print("\n" + "="*70)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø SMART AGENT")
    print("="*70)

    passed = 0
    total = len(results)

    for test_name, success in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"{test_name:<40} {status}")

        if success:
            passed += 1

    print(f"\nüìà –ò–¢–û–ì–û: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")

    if passed == total:
        print("üéâ –í–°–ï –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
        return 0
    else:
        print("‚ö†Ô∏è  –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ï–ù–´.")
        return 1


if __name__ == "__main__":
    sys.exit(run_integration_tests())