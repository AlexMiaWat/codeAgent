#!/usr/bin/env python3
"""
–¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Smart Agent
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
"""

import sys
import os
import time
import tempfile
from pathlib import Path
from unittest.mock import patch, mock_open

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))

import pytest
import json
from datetime import datetime, timedelta


def test_learning_tool_cache_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è LearningTool"""
    print("‚ö° –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è LearningTool...")

    try:
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as temp_dir:
            # –°–æ–∑–¥–∞–µ–º LearningTool —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            tool = LearningTool(
                experience_dir=temp_dir + "/experience",
                max_experience_tasks=1000,
                cache_size=500,
                cache_ttl_seconds=300
            )

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–ø—ã—Ç–∞
            start_time = time.time()

            for i in range(10):
                tool._run("save_experience", **{
                    "task_id": f"perf_test_{i:03d}",
                    "task_description": f"Performance test task {i}",
                    "success": True,
                    "execution_time": 1.0 + i * 0.1,
                    "notes": f"Test note {i}",
                    "patterns": ["performance", f"pattern_{i}"]
                })

            save_time = time.time() - start_time
            avg_save_time = save_time / 10

            print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {save_time:.4f}s (—Å—Ä–µ–¥–Ω–µ–µ: {avg_save_time:.4f}s)")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑—É–º–Ω–æ–µ (< 0.1 —Å–µ–∫)
            assert avg_save_time < 0.1, f"–°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {avg_save_time:.4f} —Å–µ–∫"

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞
            start_time = time.time()

            for i in range(20):
                result = tool._run("find_similar", **{
                    "query": f"performance test task {i % 5}",
                    "limit": 3
                })

            search_time = time.time() - start_time
            avg_search_time = search_time / 20

            print(f"   –ü–æ–∏—Å–∫: {search_time:.4f}s (—Å—Ä–µ–¥–Ω–µ–µ: {avg_search_time:.4f}s)")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ —Ä–∞–∑—É–º–Ω–æ–µ (< 0.05 —Å–µ–∫)
            assert avg_search_time < 0.05, f"–°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫: {avg_search_time:.4f} —Å–µ–∫"

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
            cache_stats = tool.get_cache_stats()
            print(f"   üìä Cache stats: {cache_stats}")

            # –û—á–∏—Å—Ç–∫–∞
            experience_file = Path(temp_dir) / "experience" / "experience.json"
            if experience_file.exists():
                experience_file.unlink()

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return False


def test_context_analyzer_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ContextAnalyzerTool"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ContextAnalyzerTool...")

    try:
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        tool = ContextAnalyzerTool(
            project_dir=".",
            max_file_size=1000000,
            supported_extensions=[".py", ".md", ".txt"]
        )

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞
        start_time = time.time()
        result = tool._run("analyze_project")
        analysis_time = time.time() - start_time

        print(f"   –ê–Ω–∞–ª–∏–∑: {analysis_time:.4f}s")
        print(f"   üìè –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –∑–∞ —Ä–∞–∑—É–º–Ω–æ–µ –≤—Ä–µ–º—è (< 5 —Å–µ–∫ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞)
        assert analysis_time < 5.0, f"–°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {analysis_time:.4f} —Å–µ–∫"

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        start_time = time.time()
        result2 = tool._run("analyze_project")  # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        cached_analysis_time = time.time() - start_time

        print(".4f"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±—ã—Å—Ç—Ä–µ–µ (—ç—Ñ—Ñ–µ–∫—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è)
        speedup = analysis_time / cached_analysis_time if cached_analysis_time > 0 else 1
        print(".2f"
        # –î–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –æ–∂–∏–¥–∞–µ–º —É—Å–∫–æ—Ä–µ–Ω–∏–µ –º–∏–Ω–∏–º—É–º –≤ 2 —Ä–∞–∑–∞
        assert speedup >= 2.0, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –æ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è: {speedup:.2f}x"

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ContextAnalyzer: {e}")
        return False


def test_smart_agent_memory_usage():
    """–¢–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ Smart Agent"""
    print("\nüß† –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ Smart Agent...")

    try:
        import psutil
        import os

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        print(".2f"
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã Smart Agent
        from src.tools.learning_tool import LearningTool
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        import_memory = process.memory_info().rss / 1024 / 1024  # MB
        import_usage = import_memory - initial_memory

        print(".2f"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–º–ø–æ—Ä—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏ (< 50 MB)
        assert import_usage < 50.0, f"–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ: {import_usage:.2f} MB"

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        with tempfile.TemporaryDirectory() as temp_dir:
            learning_tool = LearningTool(experience_dir=temp_dir + "/experience")
            context_tool = ContextAnalyzerTool(project_dir=".")

            tool_memory = process.memory_info().rss / 1024 / 1024  # MB
            tool_usage = tool_memory - import_memory

            print(".2f"
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏ (< 20 MB)
            assert tool_usage < 20.0, f"–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {tool_usage:.2f} MB"

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞–≥—Ä—É–∑–∫—É —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–¥–∞—á
            for i in range(100):
                learning_tool._run("save_experience", **{
                    "task_id": f"memory_test_{i:03d}",
                    "task_description": f"Memory test task {i}",
                    "success": True,
                    "execution_time": 1.0,
                    "notes": f"Memory test {i}",
                    "patterns": ["memory_test"]
                })

            load_memory = process.memory_info().rss / 1024 / 1024  # MB
            load_usage = load_memory - tool_memory

            print(".2f"
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç —É—Ç–µ—á–∫—É –ø–∞–º—è—Ç–∏ (< 10 MB –ø—Ä–∏—Ä–æ—Å—Ç)
            assert load_usage < 10.0, f"–í–æ–∑–º–æ–∂–Ω–∞—è —É—Ç–µ—á–∫–∞ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –Ω–∞–≥—Ä—É–∑–∫–µ: {load_usage:.2f} MB"

        return True

    except ImportError:
        print("‚ö†Ô∏è  psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
        return False


def test_cache_hit_rate_optimization():
    """–¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ hit rate –∫—ç—à–∞"""
    print("\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ hit rate –∫—ç—à–∞...")

    try:
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as temp_dir:
            # –°–æ–∑–¥–∞–µ–º LearningTool —Å –±–æ–ª—å—à–∏–º –∫—ç—à–µ–º
            tool = LearningTool(
                experience_dir=temp_dir + "/experience",
                max_experience_tasks=1000,
                cache_size=1000,
                cache_ttl_seconds=600
            )

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ–ø—ã—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
            task_templates = [
                "–°–æ–∑–¥–∞—Ç—å API endpoint –¥–ª—è {resource}",
                "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {operation}",
                "–î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –ø–æ–ª—è {field}",
                "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é {function} –≤ –º–æ–¥—É–ª–µ {module}",
                "–ò—Å–ø—Ä–∞–≤–∏—Ç—å –±–∞–≥ –≤ {component} —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å {issue}"
            ]

            resources = ["users", "products", "orders", "settings"]
            operations = ["select", "insert", "update", "delete"]
            fields = ["email", "password", "name", "date"]
            functions = ["validate", "process", "calculate", "format"]
            modules = ["utils", "models", "views", "controllers"]
            components = ["frontend", "backend", "database", "cache"]
            issues = ["encoding", "timeout", "validation", "permissions"]

            # –°–æ–∑–¥–∞–µ–º 50 —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
            for i in range(50):
                template = task_templates[i % len(task_templates)]

                # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                task_desc = template.format(
                    resource=resources[i % len(resources)],
                    operation=operations[i % len(operations)],
                    field=fields[i % len(fields)],
                    function=functions[i % len(functions)],
                    module=modules[i % len(modules)],
                    component=components[i % len(components)],
                    issue=issues[i % len(issues)]
                )

                tool._run("save_experience", **{
                    "task_id": f"diversity_test_{i:03d}",
                    "task_description": task_desc,
                    "success": True,
                    "execution_time": 2.0 + (i % 10) * 0.5,
                    "notes": f"Diversity test {i}",
                    "patterns": ["diversity", f"pattern_{(i % 5)}"]
                })

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á (–∏–º–∏—Ç–∏—Ä—É–µ–º –∫—ç—à hits)
            search_queries = [
                "–°–æ–∑–¥–∞—Ç—å API endpoint –¥–ª—è users",
                "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è select",
                "–î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –ø–æ–ª—è email",
                "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é validate –≤ –º–æ–¥—É–ª–µ utils"
            ]

            hits = 0
            total_searches = 20

            start_time = time.time()
            for i in range(total_searches):
                query = search_queries[i % len(search_queries)]
                result = tool._run("find_similar", **{
                    "query": query,
                    "limit": 3
                })
                if result and len(result) > 0:
                    hits += 1

            search_time = time.time() - start_time
            avg_search_time = search_time / total_searches
            hit_rate = hits / total_searches

            print(".1%"            print(".4f"            print(f"   üìä –í—Å–µ–≥–æ –ø–æ–∏—Å–∫–æ–≤: {total_searches}, hits: {hits}")

            # –û–∂–∏–¥–∞–µ–º hit rate > 80% –¥–ª—è —Ö–æ—Ä–æ—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à–∞
            assert hit_rate > 0.8, f"–ù–∏–∑–∫–∏–π hit rate –∫—ç—à–∞: {hit_rate:.1%}"
            # –û–∂–∏–¥–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ < 0.02 —Å–µ–∫
            assert avg_search_time < 0.02, f"–°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫: {avg_search_time:.4f} —Å–µ–∫"

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è hit rate: {e}")
        return False


def test_concurrent_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏"""
    print("\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")

    try:
        import threading
        from concurrent.futures import ThreadPoolExecutor, as_completed

        from src.tools.learning_tool import LearningTool

        results = []
        errors = []

        def worker_thread(thread_id):
            """–†–∞–±–æ—á–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Ç–æ–∫–∞"""
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    tool = LearningTool(
                        experience_dir=f"{temp_dir}/experience_{thread_id}",
                        max_experience_tasks=500
                    )

                    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ –ø–æ—Ç–æ–∫–µ
                    thread_results = []

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á
                    for i in range(5):
                        result = tool._run("save_experience", **{
                            "task_id": f"concurrent_test_{thread_id}_{i:02d}",
                            "task_description": f"Concurrent test task {thread_id}-{i}",
                            "success": True,
                            "execution_time": 1.0,
                            "notes": f"Thread {thread_id}, task {i}",
                            "patterns": [f"thread_{thread_id}", f"task_{i}"]
                        })
                        thread_results.append(result)

                    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
                    search_result = tool._run("find_similar", **{
                        "query": f"concurrent test task {thread_id}",
                        "limit": 2
                    })
                    thread_results.append(search_result)

                    return thread_results

            except Exception as e:
                errors.append(f"Thread {thread_id}: {e}")
                return None

        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        start_time = time.time()

        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(worker_thread, i) for i in range(4)]

            for future in as_completed(futures):
                result = future.result()
                if result:
                    results.extend(result)

        total_time = time.time() - start_time

        print(".2f"        print(f"   üìä –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {len(results)}")
        print(f"   ‚ùå –û—à–∏–±–æ–∫: {len(errors)}")

        if errors:
            print("   –û—à–∏–±–∫–∏:")
            for error in errors:
                print(f"     {error}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —É—Å–ø–µ—à–Ω–æ
        assert len(errors) == 0, f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ: {errors}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—â–µ–µ –≤—Ä–µ–º—è —Ä–∞–∑—É–º–Ω–æ–µ (< 10 —Å–µ–∫ –¥–ª—è 4 –ø–æ—Ç–æ–∫–æ–≤ x 6 –æ–ø–µ—Ä–∞—Ü–∏–π)
        assert total_time < 10.0, f"–°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ: {total_time:.2f} —Å–µ–∫"

        return True

    except ImportError:
        print("‚ö†Ô∏è  ThreadPoolExecutor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
        return False


def test_performance_metrics_collection():
    """–¢–µ—Å—Ç —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("\nüìà –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")

    try:
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as temp_dir:
            tool = LearningTool(
                experience_dir=temp_dir + "/experience",
                max_experience_tasks=100
            )

            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫
            operations = []

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–¥–∞—á–∏ —Å —Ä–∞–∑–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            execution_times = [0.5, 1.2, 2.8, 0.9, 3.1, 1.5, 0.7, 2.2]
            for i, exec_time in enumerate(execution_times):
                start = time.time()
                tool._run("save_experience", **{
                    "task_id": f"metrics_test_{i:02d}",
                    "task_description": f"Metrics test task {i}",
                    "success": i % 3 != 2,  # 2 –∏–∑ 3 —É—Å–ø–µ—à–Ω—ã—Ö
                    "execution_time": exec_time,
                    "notes": f"Metrics collection test {i}",
                    "patterns": ["metrics", f"type_{i % 3}"]
                })
                operations.append(("save", time.time() - start))

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            search_queries = ["metrics test", "performance", "optimization"]
            for query in search_queries:
                start = time.time()
                result = tool._run("find_similar", **{
                    "query": query,
                    "limit": 3
                })
                operations.append(("search", time.time() - start))

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            save_times = [t for op, t in operations if op == "save"]
            search_times = [t for op, t in operations if op == "search"]

            avg_save_time = sum(save_times) / len(save_times) if save_times else 0
            avg_search_time = sum(search_times) / len(search_times) if search_times else 0
            total_operations = len(operations)

            print("   üìä –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:"            print(".4f"            print(".4f"            print(f"   üî¢ –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {total_operations}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫
            assert avg_save_time < 0.1, f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫–æ: {avg_save_time:.4f}"
            assert avg_search_time < 0.05, f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫–æ: {avg_search_time:.4f}"
            assert total_operations == len(execution_times) + len(search_queries), "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç"

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            if hasattr(tool, 'get_performance_stats'):
                stats = tool.get_performance_stats()
                print(f"   üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞: {stats}")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫: {e}")
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("‚ö° –ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Smart Agent\n")

    results = []

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    results.append(("LearningTool Cache Performance", test_learning_tool_cache_performance()))
    results.append(("ContextAnalyzer Performance", test_context_analyzer_performance()))
    results.append(("Smart Agent Memory Usage", test_smart_agent_memory_usage()))
    results.append(("Cache Hit Rate Optimization", test_cache_hit_rate_optimization()))
    results.append(("Concurrent Performance", test_concurrent_performance()))
    results.append(("Performance Metrics Collection", test_performance_metrics_collection()))

    # –ò—Ç–æ–≥–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    print("\n" + "="*70)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò SMART AGENT")
    print("="*70)

    passed = 0
    total = len(results)

    for test_name, success in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print("40")
        if success:
            passed += 1

    print(f"\nüìà –ò–¢–û–ì–û: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")

    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å Smart Agent –≤ –Ω–æ—Ä–º–µ.")
        return 0
    else:
        print("‚ö†Ô∏è  –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ï–ù–´. –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.")
        return 1


if __name__ == "__main__":
    sys.exit(main())