"""
–î—ã–º–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è Smart Agent - –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
"""

import pytest
import tempfile
import json
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock


class TestSmartAgentSmoke:
    """–î—ã–º–æ–≤—ã–µ —Ç–µ—Å—Ç—ã Smart Agent"""

    def test_create_smart_agent_basic(self):
        """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è Smart Agent - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–∞"""
        try:
            from src.agents.smart_agent import create_smart_agent
            assert create_smart_agent is not None
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏ callable
            assert callable(create_smart_agent)
        except ImportError as e:
            pytest.fail(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å create_smart_agent: {e}")

    def test_smart_agent_with_tools(self):
        """–¢–µ—Å—Ç Smart Agent —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        from src.tools.learning_tool import LearningTool
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –Ω–∞–ø—Ä—è–º—É—é –≤–º–µ—Å—Ç–æ Smart Agent
            learning_tool = LearningTool(experience_dir=str(project_dir / "experience"))
            context_tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å–æ–∑–¥–∞–Ω—ã
            assert learning_tool is not None
            assert context_tool is not None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤
            assert learning_tool.__class__.__name__ == "LearningTool"
            assert context_tool.__class__.__name__ == "ContextAnalyzerTool"

    @patch('src.tools.docker_utils.DockerChecker.is_docker_available')
    def test_smart_agent_with_docker_disabled(self, mock_docker_check):
        """–¢–µ—Å—Ç Smart Agent —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º Docker"""
        mock_docker_check.return_value = False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ Docker –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã–π
        from src.tools.docker_utils import DockerChecker
        result = DockerChecker.is_docker_available()
        assert result == False


class TestLearningToolSmoke:
    """–î—ã–º–æ–≤—ã–µ —Ç–µ—Å—Ç—ã LearningTool"""

    def test_learning_tool_creation(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è LearningTool"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            assert tool is not None
            assert tool.experience_dir.exists()
            assert tool.experience_file.exists()

    def test_learning_tool_save_experience(self):
        """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–ø—ã—Ç–∞"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            result = tool.save_task_experience(
                task_id="test_task_001",
                task_description="–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–¥–∞—á–∞",
                success=True,
                execution_time=1.5
            )

            assert "—Å–æ—Ö—Ä–∞–Ω–µ–Ω" in result
            assert "—É—Å–ø–µ—à–Ω–æ" in result

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
            with open(tool.experience_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                assert len(data["tasks"]) == 1
                assert data["tasks"][0]["task_id"] == "test_task_001"

    def test_learning_tool_find_similar(self):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            tool.save_task_experience("task1", "–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª", True)
            tool.save_task_experience("task2", "–ù–∞–ø–∏—Å–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é", True)

            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é —Ñ—Ä–∞–∑—É
            result = tool.find_similar_tasks("–°–æ–∑–¥–∞—Ç—å")

            assert "–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª" in result or "–ø–æ—Ö–æ–∂–∏–µ –∑–∞–¥–∞—á–∏" in result

    def test_learning_tool_get_statistics(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            tool.save_task_experience("task1", "–ó–∞–¥–∞—á–∞ 1", True, 1.0)
            tool.save_task_experience("task2", "–ó–∞–¥–∞—á–∞ 2", False, 2.0)

            stats = tool.get_statistics()

            assert "–í—Å–µ–≥–æ –∑–∞–¥–∞—á: 2" in stats
            assert "–£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–¥–∞—á: 1" in stats
            assert "–ù–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–¥–∞—á: 1" in stats


class TestContextAnalyzerToolSmoke:
    """–î—ã–º–æ–≤—ã–µ —Ç–µ—Å—Ç—ã ContextAnalyzerTool"""

    def test_context_analyzer_creation(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è ContextAnalyzerTool"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            assert tool is not None
            assert str(tool.project_dir) == str(project_dir)

    def test_context_analyzer_project_structure(self):
        """–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            (project_dir / "src").mkdir()
            (project_dir / "docs").mkdir()
            (project_dir / "test").mkdir()

            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã
            (project_dir / "src" / "main.py").write_text("# Main file")
            (project_dir / "docs" / "README.md").write_text("# Documentation")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.analyze_project_structure()

            assert "–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã" in result
            assert "src" in result or "docs" in result or "test" in result

    def test_context_analyzer_task_context(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á–∏"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
            docs_dir = project_dir / "docs"
            docs_dir.mkdir()
            (docs_dir / "api.md").write_text("# API Documentation\nThis is about API development")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.get_task_context("—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å API")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
            assert "api.md" in result or "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è" in result or "–∫–æ–Ω—Ç–µ–∫—Å—Ç" in result

    def test_context_analyzer_find_dependencies(self):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Ñ–∞–π–ª–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π Python —Ñ–∞–π–ª —Å –∏–º–ø–æ—Ä—Ç–∞–º–∏
            test_file = project_dir / "test_module.py"
            test_file.write_text("""
import os
import sys
from pathlib import Path
""")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.find_file_dependencies("test_module.py")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–µ—Ç–æ–¥ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª –±–µ–∑ –æ—à–∏–±–æ–∫
            assert isinstance(result, str)
            assert len(result) > 0


class TestDockerCheckerSmoke:
    """–î—ã–º–æ–≤—ã–µ —Ç–µ—Å—Ç—ã DockerChecker"""

    @patch('subprocess.run')
    def test_docker_available_check(self, mock_subprocess):
        """–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Docker"""
        from src.tools.docker_utils import DockerChecker

        # –ú–æ–∫–∞–µ–º —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç Docker
        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = "Docker version 24.0.6"
        mock_subprocess.return_value = mock_result

        result = DockerChecker.is_docker_available()

        assert result == True
        assert mock_subprocess.call_count >= 2  # docker --version –∏ docker info

    @patch('subprocess.run')
    def test_docker_not_available_check(self, mock_subprocess):
        """–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Docker"""
        from src.tools.docker_utils import DockerChecker

        # –ú–æ–∫–∞–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–π –æ—Ç–≤–µ—Ç Docker
        mock_result = Mock()
        mock_result.returncode = 1
        mock_subprocess.return_value = mock_result

        result = DockerChecker.is_docker_available()

        assert result == False

    @patch('subprocess.run')
    def test_get_docker_version(self, mock_subprocess):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–∏ Docker"""
        from src.tools.docker_utils import DockerChecker

        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = "Docker version 24.0.6, build ed223bc"
        mock_subprocess.return_value = mock_result

        version = DockerChecker.get_docker_version()

        assert version == "24.0.6"

    @patch('subprocess.run')
    def test_get_running_containers(self, mock_subprocess):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
        from src.tools.docker_utils import DockerChecker

        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = "container1\ncontainer2\n"
        mock_subprocess.return_value = mock_result

        containers = DockerChecker.get_running_containers()

        assert len(containers) == 2
        assert "container1" in containers
        assert "container2" in containers


class TestDockerManagerSmoke:
    """–î—ã–º–æ–≤—ã–µ —Ç–µ—Å—Ç—ã DockerManager"""

    @patch('src.tools.docker_utils.DockerChecker.is_docker_available')
    @patch('src.tools.docker_utils.DockerChecker.is_container_running')
    @patch('subprocess.run')
    def test_docker_manager_start_container(self, mock_subprocess, mock_running, mock_available):
        """–¢–µ—Å—Ç –∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        from src.tools.docker_utils import DockerManager

        mock_available.return_value = True
        mock_running.return_value = False

        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = "container_id_123"
        mock_subprocess.return_value = mock_result

        manager = DockerManager()
        success, message = manager.start_container()

        assert success == True
        assert "started successfully" in message

    @patch('src.tools.docker_utils.DockerChecker.is_container_running')
    @patch('subprocess.run')
    def test_docker_manager_stop_container(self, mock_subprocess, mock_running):
        """–¢–µ—Å—Ç –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        from src.tools.docker_utils import DockerManager

        mock_running.return_value = True

        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = ""
        mock_subprocess.return_value = mock_result

        manager = DockerManager()
        success, message = manager.stop_container()

        assert success == True
        assert "stopped successfully" in message


class TestSmartAgentErrorHandling:
    """–¢–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ Smart Agent"""

    def test_create_smart_agent_with_invalid_project_dir(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è Smart Agent —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π –ø—Ä–æ–µ–∫—Ç–∞"""
        from src.agents.smart_agent import create_smart_agent

        with pytest.raises(Exception):
            # –ü–µ—Ä–µ–¥–∞–µ–º –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—É—Ç—å
            create_smart_agent(project_dir=Path("/nonexistent/path/that/does/not/exist"))

    def test_create_smart_agent_with_none_project_dir(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è Smart Agent —Å None –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
        from src.agents.smart_agent import create_smart_agent

        with pytest.raises(TypeError):
            create_smart_agent(project_dir=None)

    def test_smart_agent_with_corrupted_experience_file(self):
        """–¢–µ—Å—Ç Smart Agent —Å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–æ–º –æ–ø—ã—Ç–∞"""
        from src.agents.smart_agent import create_smart_agent
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –æ–ø—ã—Ç–∞
            experience_file = project_dir / "smart_experience" / "experience.json"
            experience_file.parent.mkdir(parents=True, exist_ok=True)

            with open(experience_file, 'w') as f:
                f.write("invalid json content { broken")

            # Smart Agent –¥–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª –æ–ø—ã—Ç–∞ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π
            with patch('src.tools.docker_utils.is_docker_available', return_value=False):
                with patch('src.llm.crewai_llm_wrapper.create_llm_for_crewai', return_value=None):
                    agent = create_smart_agent(project_dir=project_dir, use_llm=False)

                    assert agent is not None
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –æ–ø—ã—Ç–∞ –±—ã–ª –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω
                    assert experience_file.exists()

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –≤–∞–ª–∏–¥–Ω—ã–π JSON
                    import json
                    with open(experience_file, 'r') as f:
                        data = json.load(f)
                        assert 'version' in data

    def test_smart_agent_with_readonly_experience_dir(self):
        """–¢–µ—Å—Ç Smart Agent —Å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π –æ–ø—ã—Ç–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è —á—Ç–µ–Ω–∏—è"""
        from src.agents.smart_agent import create_smart_agent

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)
            experience_dir = project_dir / "readonly_experience"
            experience_dir.mkdir()

            # –î–µ–ª–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Ç–æ–ª—å–∫–æ –¥–ª—è —á—Ç–µ–Ω–∏—è (—Å–∏–º—É–ª—è—Ü–∏—è)
            import os
            original_mode = experience_dir.stat().st_mode
            experience_dir.chmod(0o444)  # –¢–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏–µ

            try:
                with patch('src.tools.docker_utils.is_docker_available', return_value=False):
                    with patch('src.llm.crewai_llm_wrapper.create_llm_for_crewai', return_value=None):
                        # –ê–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—à–∏–±–∫—É —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –æ–ø—ã—Ç–∞
                        agent = create_smart_agent(
                            project_dir=project_dir,
                            experience_dir=str(experience_dir),
                            use_llm=False
                        )
                        assert agent is not None  # –ê–≥–µ–Ω—Ç –≤—Å–µ —Ä–∞–≤–Ω–æ –¥–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞—Ç—å—Å—è
            finally:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∞
                experience_dir.chmod(original_mode)


class TestLearningToolErrorHandling:
    """–¢–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ LearningTool"""

    def test_learning_tool_with_invalid_json_file(self):
        """–¢–µ—Å—Ç LearningTool —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º JSON —Ñ–∞–π–ª–æ–º"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –æ–ø—ã—Ç–∞
            experience_file = Path(tmp_dir) / "experience.json"
            with open(experience_file, 'w') as f:
                f.write("not valid json {")

            tool = LearningTool(experience_dir=tmp_dir)

            # –ú–µ—Ç–æ–¥ –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–º–µ—Å—Ç–æ –∫—Ä–∞—Ö–∞
            data = tool._load_experience()
            assert isinstance(data, dict)
            assert 'version' in data  # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    def test_learning_tool_save_experience_with_invalid_data(self):
        """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–ø—ã—Ç–∞ —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            # –¢–µ—Å—Ç —Å None –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            result = tool.save_task_experience(
                task_id=None,
                task_description=None,
                success=None
            )

            assert isinstance(result, str)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–ø—ã—Ç –±—ã–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ None
            data = tool._load_experience()
            assert len(data['tasks']) == 1

    def test_learning_tool_find_similar_with_empty_experience(self):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á –≤ –ø—É—Å—Ç–æ–º –æ–ø—ã—Ç–µ"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            result = tool.find_similar_tasks("any query")

            assert isinstance(result, str)
            assert "–Ω–µ –Ω–∞–π–¥–µ–Ω—ã" in result or "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ" in result

    def test_learning_tool_get_recommendations_with_empty_experience(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ –ø—É—Å—Ç–æ–≥–æ –æ–ø—ã—Ç–∞"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            result = tool.get_recommendations("any task")

            assert isinstance(result, str)
            assert "–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç" in result

    def test_learning_tool_large_experience_file(self):
        """–¢–µ—Å—Ç LearningTool —Å –±–æ–ª—å—à–∏–º —Ñ–∞–π–ª–æ–º –æ–ø—ã—Ç–∞"""
        from src.tools.learning_tool import LearningTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            # –î–æ–±–∞–≤–ª—è–µ–º –º–Ω–æ–≥–æ –∑–∞–¥–∞—á –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞
            for i in range(100):
                tool.save_task_experience(
                    task_id=f"task_{i}",
                    task_description=f"Task description {i}",
                    success=i % 2 == 0,  # –ß–µ—Ä–µ–¥—É–µ–º —É—Å–ø–µ—Ö/–Ω–µ—É–¥–∞—á—É
                    execution_time=float(i) / 10.0,
                    patterns=[f"pattern_{i % 5}"]
                )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
            data = tool._load_experience()
            assert len(data['tasks']) == 100

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = tool.get_statistics()
            assert "–í—Å–µ–≥–æ –∑–∞–¥–∞—á: 100" in stats
            assert "–£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–¥–∞—á: 50" in stats  # –ü–æ–ª–æ–≤–∏–Ω–∞ –∏–∑ 100

    def test_learning_tool_concurrent_access_simulation(self):
        """–¢–µ—Å—Ç —Å–∏–º—É–ª—è—Ü–∏–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É –æ–ø—ã—Ç–∞"""
        from src.tools.learning_tool import LearningTool
        import threading
        import time

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = LearningTool(experience_dir=tmp_dir)

            results = []
            errors = []

            def worker(worker_id):
                try:
                    for i in range(10):
                        result = tool.save_task_experience(
                            task_id=f"worker_{worker_id}_task_{i}",
                            task_description=f"Task from worker {worker_id}",
                            success=True
                        )
                        results.append(result)
                        time.sleep(0.001)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                except Exception as e:
                    errors.append(str(e))

            # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤
            threads = []
            for i in range(5):
                t = threading.Thread(target=worker, args=(i,))
                threads.append(t)
                t.start()

            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
            for t in threads:
                t.join()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            assert len(errors) == 0, f"Errors occurred: {errors}"
            assert len(results) == 50  # 5 workers * 10 tasks each

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
            data = tool._load_experience()
            assert len(data['tasks']) == 50


class TestContextAnalyzerToolErrorHandling:
    """–¢–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ ContextAnalyzerTool"""

    def test_context_analyzer_with_nonexistent_project_dir(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π –ø—Ä–æ–µ–∫—Ç–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        # –î–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞—Ç—å—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫, –Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º
        tool = ContextAnalyzerTool(project_dir="/nonexistent/path")

        assert tool is not None
        result = tool.analyze_project_structure()
        assert isinstance(result, str)

    def test_context_analyzer_find_dependencies_nonexistent_file(self):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.find_file_dependencies("nonexistent_file.py")

            assert isinstance(result, str)
            assert "–Ω–µ –Ω–∞–π–¥–µ–Ω" in result or "not found" in result

    def test_context_analyzer_analyze_component_nonexistent(self):
        """–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.analyze_component("nonexistent_component")

            assert isinstance(result, str)
            assert "–Ω–µ –Ω–∞–π–¥–µ–Ω" in result or "not found" in result

    def test_context_analyzer_with_binary_file(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –±–∏–Ω–∞—Ä–Ω—ã–º —Ñ–∞–π–ª–æ–º"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º "–±–∏–Ω–∞—Ä–Ω—ã–π" —Ñ–∞–π–ª (—Å –Ω–µ—á–∏—Ç–∞–µ–º—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏)
            binary_file = project_dir / "binary.dat"
            with open(binary_file, 'wb') as f:
                f.write(bytes(range(256)))  # –í—Å–µ –±–∞–π—Ç—ã –æ—Ç 0 –¥–æ 255

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ê–Ω–∞–ª–∏–∑ –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª gracefully
            result = tool.analyze_component("binary.dat")
            assert isinstance(result, str)

    def test_context_analyzer_with_empty_directory(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –ø—É—Å—Ç–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.analyze_project_structure()

            assert isinstance(result, str)
            assert "–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞" in result

    def test_context_analyzer_with_nested_directories(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å –≥–ª—É–±–æ–∫–æ –≤–ª–æ–∂–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º –≥–ª—É–±–æ–∫–æ –≤–ª–æ–∂–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            deep_path = project_dir
            for i in range(10):  # 10 —É—Ä–æ–≤–Ω–µ–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
                deep_path = deep_path / f"level_{i}"
                deep_path.mkdir()
                (deep_path / f"file_{i}.py").write_text(f"# Level {i} file")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            result = tool.analyze_project_structure()

            assert isinstance(result, str)
            # –î–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–µ–∑ –ø—Ä–æ–±–ª–µ–º —Å –≥–ª—É–±–∏–Ω–æ–π

    def test_context_analyzer_get_task_context_empty_query(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á–∏ —Å –ø—É—Å—Ç—ã–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.get_task_context("")

            assert isinstance(result, str)
            # –î–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å gracefully

    def test_context_analyzer_find_related_files_empty_query(self):
        """–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å –ø—É—Å—Ç—ã–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            tool = ContextAnalyzerTool(project_dir=tmp_dir)

            result = tool.find_related_files("")

            assert isinstance(result, str)
            # –î–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å gracefully

    def test_context_analyzer_with_special_characters_in_paths(self):
        """–¢–µ—Å—Ç ContextAnalyzerTool —Å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ –≤ –ø—É—Ç—è—Ö"""
        from src.tools.context_analyzer_tool import ContextAnalyzerTool

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã —Å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ –≤ –∏–º–µ–Ω–∞—Ö
            special_files = [
                "file with spaces.py",
                "file-with-dashes.py",
                "file_with_underscores.py",
                "file(1).py",
                "file[1].py"
            ]

            for filename in special_files:
                (project_dir / filename).write_text("# Test file")

            tool = ContextAnalyzerTool(project_dir=str(project_dir))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            result = tool.analyze_project_structure()
            assert isinstance(result, str)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            for filename in special_files:
                result = tool.analyze_component(filename)
                assert isinstance(result, str)
                assert filename in result


class TestSmartAgentEdgeCases:
    """–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ Smart Agent"""

    def test_smart_agent_with_max_experience_tasks_zero(self):
        """–¢–µ—Å—Ç Smart Agent —Å max_experience_tasks=0"""
        from src.agents.smart_agent import create_smart_agent

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            with patch('src.tools.docker_utils.is_docker_available', return_value=False):
                with patch('src.llm.crewai_llm_wrapper.create_llm_for_crewai', return_value=None):
                    agent = create_smart_agent(
                        project_dir=project_dir,
                        max_experience_tasks=0,
                        use_llm=False
                    )

                    assert agent is not None
                    # LearningTool –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –≤ 0 –∑–∞–¥–∞—á

    def test_smart_agent_with_very_long_role_and_goal(self):
        """–¢–µ—Å—Ç Smart Agent —Å –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–º–∏ role –∏ goal"""
        from src.agents.smart_agent import create_smart_agent

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            long_text = "Very long text " * 100  # –ü–æ–≤—Ç–æ—Ä—è–µ–º 100 —Ä–∞–∑

            with patch('src.tools.docker_utils.is_docker_available', return_value=False):
                with patch('src.llm.crewai_llm_wrapper.create_llm_for_crewai', return_value=None):
                    agent = create_smart_agent(
                        project_dir=project_dir,
                        role=long_text,
                        goal=long_text,
                        use_llm=False
                    )

                    assert agent is not None
                    assert agent.role == long_text
                    assert agent.goal == long_text

    def test_smart_agent_with_unicode_characters(self):
        """–¢–µ—Å—Ç Smart Agent —Å Unicode —Å–∏–º–≤–æ–ª–∞–º–∏"""
        from src.agents.smart_agent import create_smart_agent

        with tempfile.TemporaryDirectory() as tmp_dir:
            project_dir = Path(tmp_dir)

            unicode_role = "–£–º–Ω—ã–π –ê–≥–µ–Ω—Ç ü§ñ"
            unicode_goal = "–í—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á–∏ —Å –ò–ò üí°"
            unicode_backstory = "–Ø - —É–º–Ω—ã–π –∞–≥–µ–Ω—Ç —Å —Ä—É—Å—Å–∫–∏–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ –∏ —ç–º–æ–¥–∑–∏ üéØ"

            with patch('src.tools.docker_utils.is_docker_available', return_value=False):
                with patch('src.llm.crewai_llm_wrapper.create_llm_for_crewai', return_value=None):
                    agent = create_smart_agent(
                        project_dir=project_dir,
                        role=unicode_role,
                        goal=unicode_goal,
                        backstory=unicode_backstory,
                        use_llm=False
                    )

                    assert agent is not None
                    assert agent.role == unicode_role
                    assert agent.goal == unicode_goal